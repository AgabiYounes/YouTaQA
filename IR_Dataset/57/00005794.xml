  <page>
    <title>Central tendency</title>
    <ns>0</ns>
    <id>5794</id>
    <revision>
      <id>942709402</id>
      <parentid>942709320</parentid>
      <timestamp>2020-02-26T10:05:35Z</timestamp>
      <contributor>
        <username>NonsensicalSystem</username>
        <id>37869476</id>
      </contributor>
      <minor />
      <comment>Reverted edits by [[Special:Contribs/49.144.194.115|49.144.194.115]] ([[User talk:49.144.194.115|talk]]) to last version by ClueBot NG</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">{{for|the graph/network concept|Centrality}}
In [[statistics]], a '''central tendency''' (or '''measure of central tendency''') is a central or typical value for a [[probability distribution]].&lt;ref name=Weisberg&gt;Weisberg H.F (1992) ''Central Tendency and Variability'', Sage University Paper Series on Quantitative Applications in the Social Sciences,  {{ISBN|0-8039-4007-6}} p.2&lt;/ref&gt; It may also be called a '''center''' or '''location''' of the distribution. Colloquially, measures of central tendency are often called ''[[averages]].'' The term ''central tendency'' dates from the late 1920s.&lt;ref name=Upton/&gt;

The most common measures of central tendency are the [[arithmetic mean]], the [[median]] and the [[Mode (statistics)|mode]]. A middle tendency can be calculated for either a finite set of values or for a theoretical distribution, such as the [[normal distribution]]. Occasionally authors use central tendency to denote &quot;the tendency of quantitative [[data]] to cluster around some central value.&quot;&lt;ref name=Upton&gt;Upton, G.; Cook, I. (2008) ''Oxford Dictionary of Statistics'', OUP {{ISBN|978-0-19-954145-4}} (entry for &quot;central tendency&quot;)&lt;/ref&gt;&lt;ref name=Dodge&gt;Dodge, Y. (2003) ''The Oxford Dictionary of Statistical Terms'', OUP for [[International Statistical Institute]]. {{ISBN|0-19-920613-9}} (entry for &quot;central tendency&quot;)&lt;/ref&gt;

The central tendency of a distribution is typically contrasted with its ''[[statistical dispersion|dispersion]]'' or ''variability''; dispersion and central tendency are the often characterized properties of distributions. Analysis may judge whether data has a strong or a weak central tendency based on its dispersion.

==Measures==

The following may be applied to one-dimensional data. Depending on the circumstances, it may be appropriate to transform the data before calculating a central tendency. Examples are squaring the values or taking logarithms. Whether a transformation is appropriate and what it should be, depend heavily on the data being analyzed.

; [[Arithmetic mean]] &lt;span style=&quot;font-weight: normal;&quot;&gt;or simply,&lt;/span&gt; mean: the sum of all measurements divided by the number of observations in the data set.
; [[Median]]: the middle value that separates the higher half from the lower half of the data set. The median and the mode are the only measures of central tendency that can be used for [[Level of measurement#Ordinal scale|ordinal data]], in which values are ranked relative to each other but are not measured absolutely.
; [[Mode (statistics)|Mode]]: the most frequent value in the data set. This is the only central tendency measure that can be used with [[Level of measurement#Nominal scale|nominal data]], which have purely qualitative category assignments.
; [[Geometric mean]]: the [[Nth root|''n''th root]] of the product of the data values, where there are ''n'' of these. This measure is valid only for data that are measured absolutely on a strictly positive scale.
; [[Harmonic mean]]: the [[Multiplicative inverse|reciprocal]] of the arithmetic mean of the reciprocals of the data values. This measure too is valid only for data that are measured absolutely on a strictly positive scale.
; [[Weighted arithmetic mean]]: an arithmetic mean that incorporates weighting to certain data elements.
; [[Truncated mean]] &lt;span style=&quot;font-weight: normal;&quot;&gt;or&lt;/span&gt; trimmed mean: the arithmetic mean of data values after a certain number or proportion of the highest and lowest data values have been discarded.
:; [[Interquartile mean]]: a truncated mean based on data within the [[interquartile range]].
; [[Midrange]]: the arithmetic mean of the maximum and minimum values of a data set.
; [[Midhinge]]: the arithmetic mean of the first and third [[quartile]]s.
; [[Trimean]]: the weighted arithmetic mean of the median and two quartiles.
; [[Winsorized mean]]: an arithmetic mean in which extreme values are replaced by values closer to the median.

Any of the above may be applied to each dimension of multi-dimensional data, but the results may not be invariant to rotations of the multi-dimensional space. In addition, there are the

; [[Geometric median]]: which minimizes the sum of distances to the data points. This is the same as the median when applied to one-dimensional data, but it is not the same as taking the median of each dimension independently. It is not invariant to different rescaling of the different dimensions.
; [[Quadratic mean]] &lt;span style=&quot;font-weight: normal;&quot;&gt;(often known as the [[root mean square]])&lt;/span&gt;: useful in engineering, but not often used in statistics. This is because it is not a good indicator of the center of the distribution when the distribution includes negative values.
; [[Simplicial depth]]: the probability that a randomly chosen [[simplex]] with vertices from the given distribution will contain the given center
; [[Tukey median]]: a point with the property that every halfspace containing it also contains many sample points

==Solutions to variational problems==
Several measures of central tendency can be characterized as solving a variational problem, in the sense of the [[calculus of variations]], namely minimizing variation from the center. That is, given a measure of [[statistical dispersion]], one asks for a measure of central tendency that minimizes variation: such that variation from the center is minimal among all choices of center. In a quip, &quot;dispersion precedes location&quot;. This center may or may not be unique. In the sense of [[Lp space|''L''&lt;sup&gt;''p''&lt;/sup&gt; spaces]], the correspondence is:
{| class=&quot;wikitable&quot;
! ''L''&lt;sup&gt;''p''&lt;/sup&gt; !! dispersion !! central tendency
|-
! ''L''&lt;sup&gt;0&lt;/sup&gt;
| [[variation ratio]]
| [[Mode (statistics)|mode]]
|-
! ''L''&lt;sup&gt;1&lt;/sup&gt;
| [[average absolute deviation]]
| [[median]]
|-
! ''L''&lt;sup&gt;1&lt;/sup&gt;
| [[average absolute deviation]]
| [[geometric median]]
|-
! ''L''&lt;sup&gt;2&lt;/sup&gt;
| [[standard deviation]]
| [[mean]]
|-
! ''L''&lt;sup&gt;∞&lt;/sup&gt;
| [[maximum deviation]]
| [[midrange]]
|}

The associated functions are called [[p-norm|''p''-norms]]: respectively 0-&quot;norm&quot;, 1-norm, 2-norm, and ∞-norm. The function corresponding to the ''L''&lt;sup&gt;0&lt;/sup&gt; space is not a norm, and is thus often referred to in quotes: 0-&quot;norm&quot;.

In equations, for a given (finite) data set ''X'', thought of as a vector &lt;math&gt;\mathbf{x} = (x_1, \ldots, x_n)&lt;/math&gt;, the dispersion about a point ''c'' is the &quot;distance&quot; from '''x''' to the constant vector &lt;math&gt;\mathbf{c} = (c, \ldots, c)&lt;/math&gt; in the ''p''-norm (normalized by the number of points ''n''):

:&lt;math&gt;f_p(c) = \left\| \mathbf{x} - \mathbf{c} \right\|_p := \bigg( \frac{1}{n} \sum_{i=1}^n \left| x_i - c\right| ^p \bigg) ^{1/p}.&lt;/math&gt;

For &lt;math&gt;p = 0&lt;/math&gt; and &lt;math&gt;p = \infty&lt;/math&gt; these functions are defined by taking limits, respectively as &lt;math&gt;p \to 0&lt;/math&gt; and &lt;math&gt;p \to \infty&lt;/math&gt;. For &lt;math&gt;p = 0&lt;/math&gt; the limiting values are &lt;math&gt;0^0 = 0&lt;/math&gt; and &lt;math&gt;a^0 = 1&lt;/math&gt; for &lt;math&gt;a \neq 0&lt;/math&gt;, so the difference becomes simply equality, so the 0-norm counts the number of ''unequal'' points. For &lt;math&gt;p = \infty&lt;/math&gt; the largest number dominates, and thus the ∞-norm is the maximum difference.

===Uniqueness===
The mean (''L''&lt;sup&gt;2&lt;/sup&gt; center) and midrange (''L''&lt;sup&gt;∞&lt;/sup&gt; center) are unique (when they exist), while the median (''L''&lt;sup&gt;1&lt;/sup&gt; center) and mode (''L''&lt;sup&gt;0&lt;/sup&gt; center) are not in general unique. This can be understood in terms of [[convex function|convexity]] of the associated functions ([[coercive function]]s).

The 2-norm and ∞-norm are [[strictly convex]], and thus (by convex optimization) the minimizer is unique (if it exists), and exists for bounded distributions. Thus standard deviation about the mean is lower than standard deviation about any other point, and the maximum deviation about the midrange is lower than the maximum deviation about any other point.

The 1-norm is not ''strictly'' convex, whereas strict convexity is needed to ensure uniqueness of the minimizer. Correspondingly, the median (in this sense of minimizing) is not in general unique, and in fact any point between the two central points of a discrete distribution minimizes average absolute deviation.

The 0-&quot;norm&quot; is not convex (hence not a norm). Correspondingly, the mode is not unique – for example, in a uniform distribution ''any'' point is the mode.

===Information geometry===
The notion of a &quot;center&quot; as minimizing variation can be generalized in [[information geometry]] as a distribution that minimizes [[divergence (statistics)|divergence]] (a generalized distance) from a data set. The most common case is [[maximum likelihood estimation]], where the maximum likelihood estimate (MLE) maximizes likelihood (minimizes expected [[surprisal]]), which can be interpreted geometrically by using [[Entropy (statistics)|entropy]] to measure variation: the MLE minimizes [[cross entropy]] (equivalently, [[relative entropy]], Kullback–Leibler divergence).

A simple example of this is for the center of nominal data: instead of using the mode (the only single-valued &quot;center&quot;), one often uses the [[empirical measure]] (the [[frequency distribution]] divided by the [[sample size]]) as a &quot;center&quot;. For example, given [[binary data]], say heads or tails, if a data set consists of 2 heads and 1 tails, then the mode is &quot;heads&quot;, but the empirical measure is 2/3 heads, 1/3 tails, which minimizes the cross-entropy (total surprisal) from the data set. This perspective is also used in [[regression analysis]], where [[least squares]] finds the solution that minimizes the distances from it, and analogously in [[logistic regression]], a maximum likelihood estimate minimizes the surprisal (information distance).

==Relationships between the mean, median and mode==
{{Main|Nonparametric skew#Relationships between the mean, median and mode}}

For [[unimodal distribution]]s the following bounds are known and are sharp:&lt;ref name=Johnson1951&gt;Johnson NL, Rogers CA (1951) &quot;The moment problem for unimodal distributions&quot;. ''Annals of Mathematical Statistics'', 22 (3) 433–439&lt;/ref&gt;

: &lt;math&gt; \frac{| \theta - \mu |}{ \sigma } \le \sqrt{ 3 } ,&lt;/math&gt;

: &lt;math&gt; \frac{| \nu - \mu |}{ \sigma } \le \sqrt{ 0.6 } ,&lt;/math&gt;

: &lt;math&gt; \frac{| \theta - \nu |}{ \sigma } \le \sqrt{ 3 } ,&lt;/math&gt;

where ''μ'' is the mean, ''ν'' is the median, ''θ'' is the mode, and ''σ'' is the standard deviation.

For every distribution,&lt;ref name=Hotelling1932&gt;Hotelling H, Solomons LM (1932) The limits of a measure of skewness. Annals Math Stat 3, 141–114&lt;/ref&gt;&lt;ref name=Garver1932&gt;Garver (1932) Concerning the limits of a mesuare of skewness. Ann Math Stats 3(4) 141–142&lt;/ref&gt;

: &lt;math&gt; \frac{| \nu - \mu |}{ \sigma } \le 1.&lt;/math&gt;

==See also==
*[[Expected value]]
*[[Location parameter]]

==References==
{{Reflist}}
{{Statistics|descriptive}}

{{DEFAULTSORT:Central Tendency}}
[[Category:Summary statistics]]
[[Category:Probability theory]]

[[de:Lagemaß]]</text>
      <sha1>lxuvrecic0aqgv1hi58urfpzc1ntn1a</sha1>
    </revision>
  </page>
