  <page>
    <title>Complexity</title>
    <ns>0</ns>
    <id>7363</id>
    <revision>
      <id>933234786</id>
      <parentid>930559068</parentid>
      <timestamp>2019-12-30T18:56:01Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead.) #IABot (v2.0</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">{{about||the use in computer science|Computational complexity|other uses|Complexity (disambiguation)}}
{{cleanup rewrite|date=June 2013}}

'''Complexity''' characterises the behaviour of a [[system]] or [[model (disambiguation)|model]] whose components interact in multiple ways and follow local rules, meaning there is no reasonable higher instruction to define the various possible interactions.&lt;ref name=&quot;steven&quot;&gt;{{cite book
| last = Johnson
| first = Steven
| title = Emergence: The Connected Lives of Ants, Brains, Cities
| publisher = Scribner
| year = 2001
| location = New York
| url = https://books.google.com/books?id=Au_tLkCwExQC
| page = 19
| isbn = 978-3411040742}}
&lt;/ref&gt;

The term is generally used to characterize something with many parts where those parts interact with each other in multiple ways, culminating in a higher order of [[emergence]] greater than the sum of its parts. The study of these complex linkages at various scales is the main goal of [[complex systems theory]].

[[Science]] {{as of | 2010 | lc = on}} takes a number of approaches to characterizing complexity; Zayed ''et al.''&lt;ref&gt;
J. M. Zayed, N. Nouvel, U. Rauwald, O. A. Scherman. ''Chemical Complexity – supramolecular self-assembly of synthetic and biological building blocks in water''. Chemical Society Reviews, 2010, 39, 2806–2816 http://pubs.rsc.org/en/Content/ArticleLanding/2010/CS/b922348g
&lt;/ref&gt;
reflect many of these. [[Neil F. Johnson|Neil Johnson]] states that &quot;even among scientists, there is no unique definition of complexity – and the scientific notion has traditionally been conveyed using particular examples...&quot;  Ultimately Johnson adopts the definition of &quot;complexity science&quot; as &quot;the study of the phenomena which emerge from a collection of interacting objects&quot;.&lt;ref name=&quot;Neil Johnson&quot;&gt;{{cite book
 |last         = Johnson
 |first        = Neil F.
 |title        = Simply complexity: A clear guide to complexity theory
 |publisher    = Oneworld Publications
 |year         = 2009
 |chapter      = Chapter 1: Two's company, three is complexity
 |page         = 3
 |chapter-url          = http://www.uvm.edu/rsenr/nr385se/readings/complexity.pdf
 |isbn         = 978-1780740492
 |access-date  = 2013-06-29
 |archive-url  = https://web.archive.org/web/20151211064454/http://www.uvm.edu/rsenr/nr385se/readings/complexity.pdf
 |archive-date = 2015-12-11
 |url-status     = dead
}}&lt;/ref&gt;

== Overview ==
Definitions of complexity often depend on the concept of a &quot;[[system]]&quot; – a set of parts or elements that have relationships among them differentiated from relationships with other elements outside the relational regime. Many definitions tend to postulate or assume that complexity expresses a condition of numerous elements in a system and numerous forms of relationships among the elements. However, what one sees as complex and what one sees as simple is relative and changes with time.

[[Warren Weaver]] posited in 1948 two forms of complexity: disorganized complexity, and organized complexity.&lt;ref name=Weaver&gt;{{Cite journal
  | last = Weaver
  | first = Warren
  | title = Science and Complexity
  | journal = American Scientist
  | volume = 36
  | pages = 536–44
  | year = 1948
  | url = http://people.physics.anu.edu.au/~tas110/Teaching/Lectures/L1/Material/WEAVER1947.pdf
  | pmid = 18882675
  | issue = 4
  | accessdate = 2007-11-21}}
&lt;/ref&gt;
Phenomena of 'disorganized complexity' are treated using probability theory and statistical mechanics, while 'organized complexity' deals with phenomena that escape such approaches and confront &quot;dealing simultaneously with a sizable number of factors which are interrelated into an organic whole&quot;.&lt;ref name=Weaver/&gt; Weaver's 1948 paper has influenced subsequent thinking about complexity.&lt;ref&gt;{{cite book
  | last = Johnson
  | first = Steven
  | title = Emergence: the connected lives of ants, brains, cities, and software
  | publisher = Scribner
  | year = 2001
  | page = 46
  | location = New York
  | isbn = 978-0-684-86875-2
  | url = https://archive.org/details/emergenceconnect00john
  }}
&lt;/ref&gt;

The approaches that embody concepts of systems, multiple elements, multiple relational regimes, and state spaces might be summarized as implying that complexity arises from the number of distinguishable relational regimes (and their associated state spaces) in a defined system.

Some definitions relate to the algorithmic basis for the expression of a complex phenomenon or model or mathematical expression, as later set out herein.

== Disorganized vs. organized ==
One of the problems in addressing complexity issues has been formalizing the intuitive conceptual distinction between the large number of variances in relationships extant in random collections, and the sometimes large, but smaller, number of relationships between elements in systems where constraints (related to correlation of otherwise independent elements) simultaneously reduce the variations from element independence and create distinguishable regimes of more-uniform, or correlated, relationships, or interactions.

Weaver perceived and addressed this problem, in at least a preliminary way, in drawing a distinction between &quot;disorganized complexity&quot; and &quot;organized complexity&quot;.

In Weaver's view, disorganized complexity results from the particular system having a very large number of parts, say millions of parts, or many more. Though the interactions of the parts in a &quot;disorganized complexity&quot; situation can be seen as largely random, the properties of the system as a whole can be understood by using probability and statistical methods.

A prime example of disorganized complexity is a gas in a container, with the gas molecules as the parts. Some would suggest that a system of disorganized complexity may be compared with the (relative) [[simplicity]] of planetary orbits – the latter can be predicted by applying [[Newton's laws of motion]]. Of course, most real-world systems, including planetary orbits, eventually become theoretically unpredictable even using Newtonian dynamics; as discovered by modern [[chaos theory]].&lt;ref&gt;&quot;Sir James Lighthill and Modern Fluid Mechanics&quot;, by Lokenath Debnath, The University of Texas-Pan American, US, Imperial College Press: {{ISBN|978-1-84816-113-9}}: {{ISBN|1-84816-113-1}}, Singapore, page 31. Online at http://cs5594.userapi.com/u11728334/docs/25eb2e1350a5/Lokenath_Debnath_Sir_James_Lighthill_and_mode.pdf{{dead link|date=August 2017 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;

Organized complexity, in Weaver's view, resides in nothing else than the non-random, or correlated, interaction between the parts. These correlated relationships create a differentiated structure that can, as a system, interact with other systems. The coordinated system manifests properties not carried or dictated by individual parts. The organized aspect of this form of complexity vis-a-vis to other systems than the subject system can be said to &quot;emerge,&quot; without any &quot;guiding hand&quot;.

The number of parts does not have to be very large for a particular system to have emergent properties. A system of organized complexity may be understood in its properties (behavior among the properties) through [[model (abstract)|modeling]] and [[simulation]], particularly [[computer simulation|modeling and simulation with computers]]. An example of organized complexity is a city neighborhood as a living mechanism, with the neighborhood people among the system's parts.&lt;ref&gt;{{cite book
  | last = Jacobs
  | first = Jane
  | title = The Death and Life of Great American Cities
  | url = https://archive.org/details/deathlifeofgre00jaco
  | url-access = registration
  | publisher = Random House
  | year = 1961
  | location = New York }}
&lt;/ref&gt;

== Sources and factors ==
There are generally rules which can be invoked to explain the origin of complexity in a given system.

The source of disorganized complexity is the large number of parts in the system of interest, and the lack of correlation between elements in the system.

In the case of self-organizing living systems, usefully organized complexity comes from beneficially mutated organisms being selected to survive by their environment for their differential reproductive ability or at least success over inanimate matter or less organized complex organisms. See e.g. [[Robert Ulanowicz]]'s treatment of ecosystems.&lt;ref&gt;Ulanowicz, Robert, &quot;Ecology, the Ascendant Perspective&quot;, Columbia, 1997&lt;/ref&gt;

Complexity of an object or system is a relative property. For instance, for many functions (problems), such a computational complexity as time of computation is smaller when multitape [[Turing machine]]s are used than when Turing machines with one tape are used. [[Random Access Machine]]s allow one to even more decrease time complexity (Greenlaw and Hoover 1998: 226), while inductive Turing machines can decrease even the complexity class of a function, language or set (Burgin 2005). This shows that tools of activity can be an important factor of complexity.

== Varied meanings ==
In several scientific fields, &quot;complexity&quot; has a precise meaning:

* In [[computational complexity theory]], the [[Computational resource|amounts of resources]] required for the execution of [[algorithm]]s is studied. The most popular types of computational complexity are the time complexity of a problem equal to the number of steps that it takes to solve an instance of the problem as a function of the [[problem size|size of the input]] (usually measured in bits), using the most efficient algorithm, and the space complexity of a problem equal to the volume of the [[computer storage|memory]] used by the algorithm (e.g., cells of the tape) that it takes to solve an instance of the problem as a function of the size of the input (usually measured in bits), using the most efficient algorithm. This allows classification of computational problems by [[complexity class]] (such as [[P (complexity)|P]], [[NP (complexity)|NP,]] etc.). An axiomatic approach to computational complexity was developed by [[Manuel Blum]]. It allows one to deduce many properties of concrete computational complexity measures, such as time complexity or space complexity, from properties of axiomatically defined measures.
* In [[algorithmic information theory]], the ''[[Kolmogorov complexity]]'' (also called ''descriptive complexity'', ''algorithmic complexity'' or ''algorithmic entropy'') of a [[string (computer science)|string]] is the length of the shortest binary [[computer program|program]] that outputs that string. [[Minimum message length]] is a practical application of this approach. Different kinds of Kolmogorov complexity are studied: the uniform complexity, prefix complexity, monotone complexity, time-bounded Kolmogorov complexity, and space-bounded Kolmogorov complexity. An axiomatic approach to Kolmogorov complexity based on [[Blum axioms]] (Blum 1967) was introduced by Mark Burgin in the paper presented for publication by [[Andrey Kolmogorov]].&lt;ref&gt;Burgin, M. (1982) Generalized Kolmogorov complexity and duality in theory of computations, Notices of the Russian Academy of Sciences, v.25, No. 3, pp. 19–23&lt;/ref&gt; The axiomatic approach encompasses other approaches to Kolmogorov complexity. It is possible to treat different kinds of Kolmogorov complexity as particular cases of axiomatically defined generalized Kolmogorov complexity. Instead of proving similar theorems, such as the basic invariance theorem, for each particular measure, it is possible to easily deduce all such results from one corresponding theorem proved in the axiomatic setting. This is a general advantage of the axiomatic approach in mathematics. The axiomatic approach to Kolmogorov complexity was further developed in the book (Burgin 2005) and applied to software metrics (Burgin and Debnath, 2003; Debnath and Burgin, 2003).
* In [[information processing]], complexity is a measure of the total number of [[property|properties]] transmitted by an object and detected by an [[observation|observer]]. Such a collection of properties is often referred to as a [[state (computer science)|state]].
* In [[physical systems]], complexity is a measure of the [[probability]] of the [[Quantum state|state vector]] of the system. This should not be confused with [[entropy (statistical thermodynamics)|entropy]]; it is a distinct mathematical measure, one in which two distinct states are never conflated and considered equal, as is done for the notion of entropy in [[statistical mechanics]].
* In [[dynamical systems]], statistical complexity measures the size of the minimum program able to statistically reproduce the patterns (configurations) contained in the data set (sequence)&lt;ref&gt;{{Cite journal |last1=Crutchfield |first1=J.P. |last2=Young |first2=K. |year=1989 |title=Inferring statistical complexity |journal=[[Physical Review Letters]] |volume=63 |issue=2 |pages=105–108|doi=10.1103/PhysRevLett.63.105 |pmid=10040781 |bibcode=1989PhRvL..63..105C }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Crutchfield |first1=J.P. |last2=Shalizi |first2=C.R. |year=1999
 |title=Thermodynamic depth of causal states: Objective complexity via minimal representations |journal=[[Physical Review E]] |volume=59 |issue=1 |pages=275–283
|doi=10.1103/PhysRevE.59.275 |bibcode=1999PhRvE..59..275C }}&lt;/ref&gt;. While the algorithmic complexity implies a deterministic description of an object (it measures the information content of an individual sequence), the statistical complexity, like [[forecasting complexity]]&lt;ref&gt;{{cite journal |last1=Grassberger |first1=P. |year=1986 |title=Toward a quantitative theory of self-generated complexity |journal=[[International Journal of Theoretical Physics]] |volume=25 |issue=9 |pages=907–938 |doi=10.1007/bf00668821|bibcode=1986IJTP...25..907G}}&lt;/ref&gt;, implies a statistical description, and refers to an ensemble of sequences generated by a certain source. Formally, the statistical complexity reconstructs a minimal model comprising the collection of all histories sharing a similar probabilistic future, and measures the [[entropy (information theory)|entropy]] of the probability distribution of the states within this model. It is a computable and observer-independent measure based only on the internal dynamics of the system, and has been used in studies of [[emergence]] and [[self-organization]]&lt;ref&gt;{{cite journal
 |last1=Prokopenko |first1=M. |last2=Boschetti |first2=F. |last3=Ryan |first3=A. |year=2009 |title=An information-theoretic primer on complexity, self-organisation and emergence |journal=Complexity |volume=15 |issue=1 |pages=11–28 |doi=10.1002/cplx.20249 |bibcode=2009Cmplx..15a..11P }}&lt;/ref&gt;. 
* In [[mathematics]], [[Krohn–Rhodes complexity]] is an important topic in the study of finite [[semigroup]]s and [[automata theory|automata]].
* In [[Network theory]] complexity is the product of richness in the connections between components of a system,&lt;ref&gt;A complex network analysis example: &quot;[http://www.martingrandjean.ch/complex-structures-and-international-organizations/ Complex Structures and International Organizations]&quot; ({{Cite journal | volume = | issue = 2| last = Grandjean| first = Martin| title = Analisi e visualizzazioni delle reti in storia. L'esempio della cooperazione intellettuale della Società delle Nazioni | journal = Memoria e Ricerca | date = 2017| pages = 371–393| url = https://www.rivisteweb.it/doi/10.14647/87204 | doi = 10.14647/87204}} See also: [https://halshs.archives-ouvertes.fr/halshs-01610098v2 French version]).&lt;/ref&gt; and defined by a very unequal distribution of certain measures (some elements being highly connected and some very few, see [[complex network]]). 
* In [[software engineering]], [[programming complexity]] is a measure of the interactions of the various elements of the software. This differs from the computational complexity described above in that it is a measure of the design of the software.
* In [[Abstract and concrete|abstract]] sense – Abstract Complexity, is based on visual structures [[perception]] &lt;ref&gt;Mariusz Stanowski (2011) Abstract Complexity Definition, Complicity 2, p.78-83 [https://ejournals.library.ualberta.ca/index.php/complicity/article/view/11156]&lt;/ref&gt; It is complexity of binary string defined as a square of features number divided by number of elements (0's and 1's). Features comprise here all distinctive arrangements of 0's and 1's. Though the features number have to be always approximated the definition is precise and meet intuitive criterion.

Other fields introduce less precisely defined notions of complexity:

* A [[complex adaptive system]] has some or all of the following attributes:&lt;ref name=&quot;Neil Johnson&quot; /&gt;
** The number of parts (and types of parts) in the system and the number of relations between the parts is non-trivial – however, there is no general rule to separate &quot;trivial&quot; from &quot;non-trivial&quot;;
** The system has memory or includes [[feedback]];
** The system can adapt itself according to its history or feedback;
** The relations between the system and its environment are non-trivial or non-linear;
** The system can be influenced by, or can adapt itself to, its environment;
** The system is highly sensitive to initial conditions.

== Study ==
Complexity has always been a part of our environment, and therefore many scientific fields have dealt with complex systems and phenomena. From one perspective, that which is somehow complex – displaying variation without being [[randomness|random]] – is most worthy of interest given the rewards found in the depths of exploration.

The use of the term complex is often confused with the term complicated. In today's systems, this is the difference between myriad connecting &quot;stovepipes&quot; and effective &quot;integrated&quot; solutions.&lt;ref&gt;[[Lissack, Michael R.]]; [[Johan Roos]] (2000). ''The Next Common Sense, The e-Manager's Guide to Mastering Complexity.'' Intercultural Press. {{ISBN|978-1-85788-235-3}}.
&lt;/ref&gt; This means that complex is the opposite of independent, while complicated is the opposite of simple.

While this has led some fields to come up with specific definitions of complexity, there is a more recent movement to regroup observations [[interdisciplinarity|from different fields]] to study complexity in itself, whether it appears in [[anthill]]s, [[human brain]]s, or [[stock market]]s, social systems&lt;ref&gt;{{Cite journal|url=https://www.academia.edu/30193748|title=Complexics as a meta-transdisciplinary field|last=Bastardas-Boada|first=Albert|date=|journal=Congrès Mondial Pour la Pensée Complexe. Les Défis d'Un Monde Globalisé. (Paris, 8-9 Décembre). Unesco|access-date=}}&lt;/ref&gt;. One such interdisciplinary group of fields is [[relational order theories]].

== Topics ==

=== Behaviour ===
The behavior of a complex system is often said to be due to emergence and [[self-organization]]. Chaos theory has investigated the sensitivity of systems to variations in initial conditions as one cause of complex behaviour.

===Mechanisms ===
Recent developments around [[artificial life]], [[evolutionary computation]] and [[genetic algorithm]]s have led to an increasing emphasis on complexity and [[complex adaptive systems]].

=== Simulations ===
In [[social science]], the study on the emergence of macro-properties from the micro-properties, also known as macro-micro view in [[sociology]]. The topic is commonly recognized as [[social complexity]] that is often related to the use of computer simulation in social science, i.e.: [[computational sociology]].

=== Systems ===
{{main article|Complex system}}
[[Systems theory]] has long been concerned with the study of [[complex system]]s (in recent times, ''complexity theory'' and ''complex systems'' have also been used as names of the field). These systems are present in the research of a variety disciplines, including [[biology]], [[economics]], social studies and [[technology]]. Recently, complexity has become a natural domain of interest of real world socio-cognitive systems and emerging [[systemics]] research. Complex systems tend to be high-[[dimension]]al, [[non-linearity|non-linear]], and difficult to model. In specific circumstances, they may exhibit low-dimensional behaviour.

=== Data ===
In [[information theory]], algorithmic information theory is concerned with the complexity of strings of data.

Complex strings are harder to compress. While intuition tells us that this may depend on the [[codec]] used to compress a string (a codec could be theoretically created in any arbitrary language, including one in which the very small command &quot;X&quot; could cause the computer to output a very complicated string like &quot;18995316&quot;), any two [[Turing completeness|Turing-complete]] languages can be implemented in each other, meaning that the length of two encodings in different languages will vary by at most the length of the &quot;translation&quot; language – which will end up being negligible for sufficiently large data strings.

These algorithmic measures of complexity tend to assign high values to [[signal noise|random noise]]. However, those studying complex systems would not consider randomness as complexity{{who|date=October 2013}}.

[[Information entropy]] is also sometimes used in information theory as indicative of complexity.

Recent work in [[machine learning]] has examined the complexity of the data as it affects the performance of [[Supervised learning|supervised]] classification algorithms. Ho and Basu present a set of [[Computational complexity theory|complexity measures]] for [[binary classification]] problems.&lt;ref&gt;Ho, T.K.; Basu, M. (2002). &quot;[http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990132&amp;tag=1 Complexity Measures of Supervised Classification Problems]&quot;. IEEE Transactions on Pattern Analysis and Machine Intelligence 24 (3), pp 289–300.&lt;/ref&gt;

The complexity measures broadly cover:
* the overlaps in feature values from differing classes.
* the separability of the classes.
* measures of geometry, topology, and density of [[manifold]]s. Instance hardness is another approach seeks to characterize the data complexity with the goal of determining how hard a data set is to classify correctly and is not limited to binary problems.&lt;ref&gt;Smith, M.R.; Martinez, T.; Giraud-Carrier, C. (2014). &quot;[https://link.springer.com/article/10.1007%2Fs10994-013-5422-z An Instance Level Analysis of Data Complexity]&quot;. Machine Learning, 95(2): 225–256.&lt;/ref&gt; 
Instance hardness is a bottom-up approach that first seeks to identify instances that are likely to be misclassified (or, in other words, which instances are the most complex). The characteristics of the instances that are likely to be misclassified are then measured based on the output from a set of hardness measures. The hardness measures are based on several supervised learning techniques such as measuring the number of disagreeing neighbors or the likelihood of the assigned class label given the input features. The information provided by the complexity measures has been examined for use in [[Meta learning (computer science)|meta learning]] to determine for which data sets filtering (or removing suspected noisy instances from the training set) is the most beneficial&lt;ref&gt;{{cite journal|title= Predicting Noise Filtering Efficacy with Data Complexity Measures for Nearest Neighbor Classification|journal= Pattern Recognition|volume= 46|pages= 355–364|doi= 10.1016/j.patcog.2012.07.009|year= 2013|last1= Sáez|first1= José A.|last2= Luengo|first2= Julián|last3= Herrera|first3= Francisco}}&lt;/ref&gt; and could be expanded to other areas.

=== In molecular recognition ===
A recent study based on molecular simulations and compliance constants describes [[molecular recognition]] as a phenomenon of organisation.&lt;ref&gt;{{cite journal | title=Complexity in molecular recognition | author=Jorg Grunenberg | journal=Phys. Chem. Chem. Phys. | year=2011 | volume=13 | issue=21 | pages= 10136–10146 | doi=10.1039/c1cp20097f| pmid=21503359 | bibcode=2011PCCP...1310136G }}&lt;/ref&gt;
Even for small molecules like [[carbohydrates]], the recognition process can not be predicted or designed even assuming that each individual [[hydrogen bond]]'s strength is exactly known.

== Applications ==
Computational complexity theory is the study of the complexity of problems – that is, the difficulty of [[problem solving|solving]] them. Problems can be classified by complexity class according to the time it takes for an algorithm – usually a computer program – to solve them as a function of the problem size. Some problems are difficult to solve, while others are easy. For example, some difficult problems need algorithms that take an exponential amount of time in terms of the size of the problem to solve. Take the [[travelling salesman problem]], for example. It can be solved in time &lt;math&gt;O(n^2 2^n)&lt;/math&gt; (where ''n'' is the size of the network to visit – the number of cities the travelling salesman must visit exactly once). As the size of the network of cities grows, the time needed to find the route grows (more than) exponentially.

Even though a problem may be computationally solvable in principle, in actual practice it may not be that simple. These problems might require large amounts of time or an inordinate amount of space. [[Analysis of algorithms|Computational complexity]] may be approached from many different aspects. Computational complexity can be investigated on the basis of time, memory or other resources used to solve the problem. Time and space are two of the most important and popular considerations when problems of complexity are analyzed.

There exist a certain class of problems that although they are solvable in principle they require so much time or space that it is not practical to attempt to solve them. These problems are called [[Computational complexity theory#Intractability|intractable]].

There is another form of complexity called [[Model of hierarchical complexity|hierarchical complexity]]. It is orthogonal to the forms of complexity discussed so far, which are called horizontal complexity.

== See also ==
{{Div col|colwidth=18em}}
* [[Chaos theory]]
* [[Command and Control Research Program]]
* [[Complex systems]]
* [[Complexity theory (disambiguation)|Complexity theory]] (disambiguation page)
* [[Cyclomatic complexity]]
* [[Digital morphogenesis]]
* [[Dual-phase evolution]]
* [[Emergence]]
* [[Evolution of complexity]]
* [[Game complexity]]
* [[Holism in science]]
* [[Law of Complexity/Consciousness]]
* [[Model of hierarchical complexity]]
* [[Names of large numbers]]
* [[Network science]]
* [[Network theory]]
* [[Novelty theory]]
* [[Occam's razor]]
* [[Process architecture]]
* [[Programming Complexity]]
* [[Sociology and complexity science]]
* [[Systems theory]]
* [[Thorngate's postulate of commensurate complexity]]
* [[Variety (cybernetics)]]
* [[Volatility, uncertainty, complexity and ambiguity]]
* [[Computational irreducibility]]
*[[Zero-Force Evolutionary Law]]
{{Div col end}}

== References ==
{{reflist}}

== Further reading ==
{{refbegin}}
* {{cite journal
  | last = Chu
  | first = Dominique
  | title = Complexity: Against Systems
  | journal = Theory in Biosciences
  | volume = 130
  | issue = 3
  | pages = 229–45
  | year = 2011
  | pmid =21287293  | doi = 10.1007/s12064-011-0121-4
  | url = http://kar.kent.ac.uk/30776/1/againstSystems.pdf
  }}
* {{cite book
  | last = Waldrop
  | first = M. Mitchell
  | authorlink = 
  | title = Complexity: The Emerging Science at the Edge of Order and Chaos
  | location = New York
  | publisher = Simon &amp; Schuster
  | year = 1992
  | isbn = 978-0-671-76789-1
  | url = https://archive.org/details/complexityemergi00wald
  }}
* {{cite book
  | last = Czerwinski
  | first = Tom
  |author2=David Alberts
  | title = Complexity, Global Politics, and National Security
  | url = http://www.dodccrp.org/files/Alberts_Complexity_Global.pdf
  | publisher = National Defense University
  | year = 1997
  | isbn = 978-1-57906-046-6 }}
* {{cite book
  | last = Solé
  | first = R. V.
  |author2=B. C. Goodwin
  | title = Signs of Life: How Complexity Pervades Biology
  | publisher = Basic Books
  | year = 2002
  | isbn = 978-0-465-01928-1 }}
* {{Cite book
  | first = Francis
  | last =[[Francis Heylighen|Heylighen]]
  | editor-last = Bates
  | editor-first = Marcia J.
  | editor2-last = Maack
  | editor2-first = Mary Niles
  | contribution = Complexity and Self-Organization
  | contribution-url = http://pespmc1.vub.ac.be/Papers/ELIS-Complexity.pdf
  | title = Encyclopedia of Library and Information Sciences
  | year = 2008
  | publisher = CRC
  | isbn = 978-0-8493-9712-7
  }}
* Burgin, M. (1982) Generalized Kolmogorov complexity and duality in theory of computations, Notices of the Russian Academy of Sciences, v.25, No. 3, pp.&amp;nbsp;19–23
* Meyers, R.A., (2009) &quot;Encyclopedia of Complexity and Systems Science&quot;, {{ISBN|978-0-387-75888-6}}
* Mitchell, M. (2009). Complexity: A Guided Tour. Oxford University Press, Oxford, UK.
* Gershenson, C., Ed. (2008). Complexity: 5 Questions. Automatic Peess / VIP.
{{refend}}

== External links ==
{{wikiquote}}
{{Wiktionary}}
* [http://bactra.org/notebooks/complexity-measures.html Complexity Measures] – an article about the abundance of not-that-useful complexity measures.
* [http://web.cecs.pdx.edu/~mm/ExploringComplexityFall2009/index.html Exploring Complexity in Science and Technology] – Introductory complex system course by Melanie Mitchell
* [http://www.santafe.edu/ Santa Fe Institute] focusing on the study of complexity science: [https://web.archive.org/web/20110304121331/http://www.santafe.edu/research/videos/catalog/ Lecture Videos]
* [https://web.archive.org/web/20061009004757/http://eclectic.ss.uci.edu/~drwhite/center/cac.html UC Four Campus Complexity Videoconferences] – Human Sciences and Complexity

{{chaos theory|state=collapsed}}

{{Authority control}}

[[Category:Abstraction]]
[[Category:Complex systems theory]]
[[Category:Holism]]
[[Category:Systems]]
[[Category:Transdisciplinarity]]</text>
      <sha1>scm4uj510wsh8y0c5tw05s0w87yevcw</sha1>
    </revision>
  </page>
