  <page>
    <title>Bayesian probability</title>
    <ns>0</ns>
    <id>4890</id>
    <revision>
      <id>942312399</id>
      <parentid>941964226</parentid>
      <timestamp>2020-02-23T22:49:11Z</timestamp>
      <contributor>
        <username>Ladislav Mecir</username>
        <id>596030</id>
      </contributor>
      <comment>add missing space</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">{{broader|Bayesian statistics}}
{{Bayesian statistics}}{{Short description|Interpretation of probability}}'''Bayesian probability''' is an [[Probability interpretations|interpretation of the concept of probability]], in which, instead of [[frequentist probability|frequency]] or [[propensity probability|propensity]] of some phenomenon, probability is interpreted as reasonable expectation&lt;ref&gt;{{Cite journal |last=Cox |first=R.T. |author-link=Richard Threlkeld Cox |doi=10.1119/1.1990764 |title=Probability, Frequency, and Reasonable Expectation |journal=American Journal of Physics |volume=14 |issue=1 |pages=1–10 |year=1946 |ref=harv|bibcode=1946AmJPh..14....1C }}&lt;/ref&gt; representing a state of knowledge&lt;ref name=&quot;ghxaib&quot;&gt;{{cite book |author=Jaynes, E.T. |year=1986 |contribution=Bayesian Methods: General Background |title=Maximum-Entropy and Bayesian Methods in Applied Statistics |editor=Justice, J. H. |location=Cambridge |publisher=Cambridge University Press|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1055}}&lt;/ref&gt; or as quantification of a personal belief.&lt;ref name=&quot;Finetti, B. 1974&quot;&gt;{{cite book |last1=de Finetti |first1=Bruno |title=Theory of Probability: A critical introductory treatment |year=2017 |publisher=John Wiley &amp; Sons Ltd. |location=Chichester|isbn=9781119286370}}&lt;/ref&gt;

The Bayesian interpretation of probability can be seen as an extension of [[propositional logic]] that enables reasoning with hypotheses,&lt;ref name=&quot;Hailperin, T. 1996&quot;&gt;{{cite book |last1=Hailperin |first1=Theodore |title=Sentential Probability Logic: Origins, Development, Current Status, and Technical Applications |year=1996 |publisher=Associated University Presses|location=London|isbn=0934223459}}&lt;/ref&gt; that is to say, with propositions whose [[truth value|truth or falsity]] is unknown. In the Bayesian view, a probability is assigned to a hypothesis, whereas under [[frequentist inference]], a hypothesis is typically tested without being assigned a probability.

Bayesian probability belongs to the category of evidential probabilities; to evaluate the probability of a hypothesis, the Bayesian probabilist specifies a [[prior probability]]. This, in turn, is then updated to a [[posterior probability]] in the light of new, relevant [[data]] (evidence).&lt;ref name=&quot;paulos&quot;&gt;{{cite web |author-link=John Allen Paulos |last=Paulos |first=John Allen |url=https://www.nytimes.com/2011/08/07/books/review/the-theory-that-would-not-die-by-sharon-bertsch-mcgrayne-book-review.html |title=The Mathematics of Changing Your Mind [by Sharon Bertsch McGrayne] |department=Book Review |newspaper=New York Times |date=5 August 2011 |access-date=2011-08-06}}&lt;/ref&gt; The Bayesian interpretation provides a standard set of procedures and formulae to perform this calculation.

The term ''Bayesian'' derives from the 18th&amp;nbsp;century mathematician and theologian [[Thomas Bayes]], who provided the first mathematical treatment of a non-trivial problem of statistical [[data analysis]] using what is now known as [[Bayesian inference]].&lt;ref name=&quot;HOS&quot;&gt;{{cite book |last1=Stigler |first1=Stephen M. |title=The history of statistics |date=March 1990 |publisher=Harvard University Press |isbn=9780674403413}}&lt;/ref&gt;{{rp|131}} Mathematician [[Pierre-Simon Laplace]] pioneered and popularised what is now called Bayesian probability.&lt;ref name=&quot;HOS&quot; /&gt;{{rp|97–98}}

==Bayesian methodology==
Bayesian methods are characterized by concepts and procedures as follows:
* The use of [[random variable]]s, or more generally unknown quantities,&lt;ref name=&quot;rbp&quot;/&gt; to model all sources of [[uncertainty]] in statistical models including uncertainty resulting from lack of information (see also [[Uncertainty quantification#Aleatoric and epistemic uncertainty|aleatoric and epistemic uncertainty]]).
* The need to determine the prior probability distribution taking into account the available (prior) information.
* The sequential use of [[Bayes' formula]]: when more data become available, calculate the posterior distribution using Bayes' formula; subsequently, the posterior distribution becomes the next prior.
* While for the frequentist, a [[null hypothesis|hypothesis]] is a [[Proposition#Treatment in logic|proposition]] (which must be [[principle of bivalence|either true or false]]) so that the frequentist probability of a hypothesis is either 0 or 1, in Bayesian statistics, the probability that can be assigned to a hypothesis can also be in a range from 0 to 1 if the truth value is uncertain.

==Objective and subjective Bayesian probabilities==
Broadly speaking, there are two interpretations on Bayesian probability. For ''[[Objectivity (philosophy)|objectivists]]'', interpreting probability as extension of [[logic]], ''probability'' quantifies the reasonable expectation everyone (even a &quot;robot&quot;) sharing the same knowledge should share in accordance with the rules of Bayesian statistics, which can be justified by [[Cox's theorem]].&lt;ref name=&quot;ghxaib&quot; /&gt;&lt;ref name = &quot;vkdmsn&quot;&gt;{{cite book |last1=Cox |first1=Richard T. |title=The algebra of probable inference| date=1961 |publisher=Johns Hopkins Press; Oxford University Press [distributor] |location=Baltimore, MD; London, UK |isbn=9780801869822 |edition=Reprint}}&lt;/ref&gt; For ''[[Subjectivism|subjectivists]]'', ''probability'' corresponds to a personal belief.&lt;ref name=&quot;Finetti, B. 1974&quot; /&gt; Rationality and coherence allow for substantial variation within the constraints they pose; the constraints are justified by the [[Dutch book]] argument or by [[decision theory]] and [[de Finetti's theorem]].&lt;ref name=&quot;Finetti, B. 1974&quot; /&gt; The objective and subjective variants of Bayesian probability differ mainly in their interpretation and construction of the prior probability.

==History==
{{Main|History of statistics#Bayesian statistics}}

The term ''Bayesian'' derives from [[Thomas Bayes]] (1702–1761), who proved a special case of what is now called [[Bayes' theorem]] in a paper titled &quot;[[An Essay towards solving a Problem in the Doctrine of Chances]]&quot;.&lt;ref&gt;{{cite book |author=McGrayne, Sharon Bertsch |year=2011 |title=The Theory that Would not Die |url=https://archive.org/details/theorythatwouldn0000mcgr |url-access=registration |at={{Google books|_Kx5xVGuLRIC|&amp;nbsp;|page=[https://archive.org/details/theorythatwouldn0000mcgr/page/10 10]}} }}&lt;/ref&gt; In that special case, the prior and posterior distributions were [[beta distribution]]s and the data came from [[Bernoulli trial]]s. It was [[Pierre-Simon Laplace]] (1749–1827) who introduced a general version of the theorem and used it to approach problems in [[celestial mechanics]], medical statistics, [[Reliability (statistics)|reliability]], and [[jurisprudence]].&lt;ref&gt;{{cite book |author=Stigler, Stephen M. |year=1986 |title=The History of Statistics |url=https://archive.org/details/historyofstatist00stig |url-access=registration |publisher=Harvard University Press |chapter=Chapter&amp;nbsp;3}}&lt;/ref&gt; Early Bayesian inference, which used uniform priors following Laplace's [[principle of insufficient reason]], was called &quot;[[inverse probability]]&quot; (because it [[Inductive reasoning|infer]]s backwards from observations to parameters, or from effects to causes).&lt;ref name=Fienberg2006&gt;{{cite journal |author=Fienberg, Stephen. E. |year=2006 |url=http://ba.stat.cmu.edu/journal/2006/vol01/issue01/fienberg.pdf |title=When did Bayesian Inference become &quot;Bayesian&quot;? |archive-url=https://web.archive.org/web/20140910070556/http://ba.stat.cmu.edu/journal/2006/vol01/issue01/fienberg.pdf |archive-date=10 September 2014 |journal=Bayesian Analysis |volume=1 |issue=1 |pages=5, 1–40}}&lt;/ref&gt; After the 1920s, &quot;inverse probability&quot; was largely supplanted by a collection of methods that came to be called [[frequentist statistics]].&lt;ref name=Fienberg2006/&gt;

In the 20th century, the ideas of Laplace developed in two directions, giving rise to ''objective'' and ''subjective'' currents in Bayesian practice.
[[Harold Jeffreys]]' ''Theory of Probability'' (first published in 1939) played an important role in the revival of the Bayesian view of probability, followed by works by [[Abraham Wald]] (1950) and [[Leonard J. Savage]] (1954). The adjective ''Bayesian'' itself dates to the 1950s;  the derived ''Bayesianism'', ''neo-Bayesianism'' is of 1960s coinage.&lt;ref&gt;{{cite journal |quote=The works of [[Abraham Wald|Wald]], ''Statistical Decision Functions'' (1950) and [[Leonard J. Savage|Savage]], ''The Foundation of Statistics'' (1954) are commonly regarded starting points for current Bayesian approaches |title=Recent developments of the so-called Bayesian approach to statistics |first=Marshall Dees |last=Harris |journal=Legal-Economic Research |publisher=University of Iowa |department=Agricultural Law Center |year=1959 |pages=125 (fn. #52), 126}}&lt;/ref&gt;&lt;ref&gt;{{cite book |quote=This revolution, which may or may not succeed, is neo-Bayesianism. Jeffreys tried to introduce this approach, but did not succeed at the time in giving it general appeal. |title=Annals of the Computation Laboratory of Harvard University |volume=31 |year=1962 |page=180}}&lt;/ref&gt;&lt;ref&gt;{{cite conference |quote=It is curious that even in its activities unrelated to ethics, humanity searches for a religion. At the present time, the religion being 'pushed' the hardest is Bayesianism. |first=Oscar |last=Kempthorne |title=The Classical Problem of Inference—Goodness of Fit |conference=Fifth Berkeley Symposium on Mathematical Statistics and Probability |year=1967 |url=https://books.google.com/books?id=IC4Ku_7dBFUC&amp;pg=PA235#v=onepage |page=235}}&lt;/ref&gt; In the objectivist stream, the statistical analysis depends on only the model assumed and the data analysed.&lt;ref name=Bernardo&gt;{{cite book |last1=Bernardo |first1=J.M. |authorlink =José-Miguel Bernardo |year=2005 |title=Reference analysis |journal=Handbook of Statistics |volume=25 |pages=17–90 |doi=10.1016/S0169-7161(05)25002-2 |isbn=9780444515391}}&lt;/ref&gt; No subjective decisions need to be involved. In contrast, &quot;subjectivist&quot; statisticians deny the possibility of fully objective analysis for the general case.

In the 1980s, there was a dramatic growth in research and applications of Bayesian methods, mostly attributed to the discovery of [[Markov chain Monte Carlo]] methods and the consequent removal of many of the computational problems, and to an increasing interest in nonstandard, complex applications.&lt;ref&gt;{{cite journal |author=Wolpert, R.L. |year=2004 |title=A conversation with James O. Berger |journal=Statistical Science |volume=9 |pages=205–218}}&lt;/ref&gt; While frequentist statistics remains strong (as seen by the fact that most undergraduate teaching is still based on it &lt;ref&gt;{{cite conference |authorlink=José-Miguel Bernardo |author=Bernardo, José M. |year=2006 |url=http://www.ime.usp.br/~abe/ICOTS7/Proceedings/PDFs/InvitedPapers/3I2_BERN.pdf |title=A Bayesian mathematical statistics primer |conference=ICOTS-7 |location=Bern}}&lt;/ref&gt;{{citation needed|date=August 2012}}), Bayesian methods are widely accepted and used, e.g., in the field of [[machine learning]].&lt;ref name=&quot;ReferenceA&quot;&gt;{{cite book |author=Bishop, C.M. |title=Pattern Recognition and Machine Learning |publisher=Springer |year=2007}}&lt;/ref&gt;

==Justification of Bayesian probabilities==
The use of Bayesian probabilities as the basis of [[Bayesian inference]] has been supported by several arguments, such as [[Cox's theorem|Cox axioms]], the [[Dutch book|Dutch book argument]], arguments based on [[decision theory]] and [[de Finetti's theorem]].

===Axiomatic approach===
[[Richard Threlkeld Cox|Richard T. Cox]] showed that&lt;ref name = &quot;vkdmsn&quot; /&gt; Bayesian updating follows from several axioms, including two [[functional equations]] and a hypothesis of differentiability. The assumption of differentiability or even continuity is controversial; Halpern found a counterexample based on his observation that the Boolean algebra of statements may be finite.&lt;ref&gt;{{cite journal |author=Halpern, J. |title=A counterexample to theorems of Cox and Fine |journal=Journal of Artificial Intelligence Research |volume=10 |pages=67–85|url=http://www.cs.cornell.edu/info/people/halpern/papers/cox.pdf}}&lt;/ref&gt; Other axiomatizations have been suggested by various authors with the purpose of making the theory more rigorous.&lt;ref name=&quot;rbp&quot;&gt;{{cite journal |author1=Dupré, Maurice J. |author2=Tipler, Frank J. |url=http://projecteuclid.org/download/pdf_1/euclid.ba/1340369856 |title=New axioms for rigorous Bayesian probability |journal=Bayesian Analysis |year=2009 |issue=3 |pages=599–606}}&lt;/ref&gt;

===Dutch book approach===
The Dutch book argument was proposed by de Finetti; it is based on betting. A [[Dutch book]] is made when a clever gambler places a set of bets that guarantee a profit, no matter what the outcome of the bets. If a [[bookmaker]] follows the rules of the Bayesian calculus in the construction of his odds, a Dutch book cannot be made.

However, [[Ian Hacking]] noted that traditional Dutch book arguments did not specify Bayesian updating: they left open the possibility that non-Bayesian updating rules could avoid Dutch books. For example, [[Ian Hacking|Hacking]] writes&lt;ref&gt;Hacking (1967), Section 3, page 316&lt;/ref&gt;&lt;ref&gt;Hacking (1988, page 124)&lt;/ref&gt; &quot;And neither the Dutch book argument, nor any other in the personalist arsenal of proofs of the probability axioms, entails the dynamic assumption. Not one entails Bayesianism. So the personalist requires the dynamic assumption to be Bayesian. It is true that in consistency a personalist could abandon the Bayesian model of learning from experience. Salt could lose its savour.&quot;

In fact, there are non-Bayesian updating rules that also avoid Dutch books (as discussed in the literature on &quot;[[probability kinematics]]&quot;&lt;ref&gt;{{cite journal |last=Skyrms |first=Brian |date=1987-01-01 |title=Dynamic Coherence and Probability Kinematics |journal=Philosophy of Science |volume=54 |issue=1 |pages=1–20 |doi=10.1086/289350 |jstor=187470 |citeseerx=10.1.1.395.5723 |df=dmy-all}}&lt;/ref&gt; following the publication of [[Richard Jeffrey|Richard C. Jeffreys]]' rule, which is itself regarded as Bayesian&lt;ref&gt;{{cite web |url=http://plato.stanford.edu/entries/bayes-theorem/ |title=Bayes' Theorem |publisher =stanford.edu |accessdate= |df=dmy-all|last = Joyce|first = James|work= The Stanford Encyclopedia of Philosophy |date =30 September 2003 }}&lt;/ref&gt;). The additional hypotheses sufficient to (uniquely) specify Bayesian updating are substantial&lt;ref&gt;{{Cite book |title=Probability in Physics |last1=Fuchs |first1=Christopher A. |last2=Schack |first2=Rüdiger |date=2012-01-01 |publisher=Springer Berlin Heidelberg |isbn=9783642213281 |editor-last1=Ben-Menahem |editor-first1=Yemima |series=The Frontiers Collection |pages=233–247 |language=en |arxiv=1103.5950 |doi=10.1007/978-3-642-21329-8_15 |editor-last2=Hemmo |editor-first2=Meir |df=dmy-all}}&lt;/ref&gt; and not universally seen as satisfactory.&lt;ref&gt;{{cite book |author-link=Bas van Fraassen |last=van Frassen |first=Bas |year=1989 |title=Laws and Symmetry |publisher=Oxford University Press |ISBN=0-19-824860-1}}&lt;/ref&gt;

===Decision theory approach===
A [[statistical decision theory|decision-theoretic]] justification of the use of Bayesian inference (and hence of Bayesian probabilities) was given by [[Abraham Wald]], who proved that every [[admissible decision rule|admissible]] statistical procedure is either a Bayesian procedure or a limit of Bayesian procedures.&lt;ref&gt;{{cite book |author=Wald, Abraham |title=Statistical Decision Functions |publisher=Wiley |year=1950}}&lt;/ref&gt; Conversely, every Bayesian procedure is [[admissible decision rule|admissible]].&lt;ref&gt;{{cite book |author1=Bernardo, José M. |author2=Smith, Adrian F.M. |title=Bayesian Theory |publisher=John Wiley |year=1994 |ISBN=0-471-92416-4}}&lt;/ref&gt;

==Personal probabilities and objective methods for constructing priors==
Following the work on [[expected utility]] [[optimal decision|theory]] of [[Frank P. Ramsey|Ramsey]] and [[John von Neumann|von Neumann]],  decision-theorists have accounted for [[optimal decision|rational behavior]] using a probability distribution for the [[Agent-based model|agent]]. Johann Pfanzagl completed the ''[[Theory of Games and Economic Behavior]]'' by providing an axiomatization of subjective probability and utility, a task left uncompleted by von Neumann and [[Oskar Morgenstern]]: their original theory supposed that all the agents had the same probability distribution, as a convenience.&lt;ref&gt;Pfanzagl (1967, 1968)&lt;/ref&gt; Pfanzagl's axiomatization was endorsed by Oskar Morgenstern: &quot;Von Neumann and I have anticipated ... [the question whether probabilities] might, perhaps more typically, be subjective and have stated specifically that in the latter case axioms could be found from which could derive the desired numerical utility together with a number for the probabilities (cf. p. 19 of The [[Theory of Games and Economic Behavior]]). We did not carry this out; it was demonstrated by Pfanzagl ... with all the necessary rigor&quot;.&lt;ref&gt;Morgenstern (1976, page 65)&lt;/ref&gt;

Ramsey and [[Leonard Jimmie Savage|Savage]] noted that the individual agent's probability distribution could be objectively studied in experiments. Procedures for [[statistical hypothesis testing|testing hypotheses]] about probabilities (using finite samples) are due to [[Frank P. Ramsey|Ramsey]] (1931) and [[Bruno de Finetti|de Finetti]] (1931, 1937, 1964, 1970). Both [[Bruno de Finetti]]&lt;ref&gt;{{Cite journal |last=Galavotti |first=Maria Carla |date=1989-01-01 |title=Anti-Realism in the Philosophy of Probability: Bruno de Finetti's Subjectivism |journal=Erkenntnis |volume=31 |issue=2/3 |pages=239–261 |doi=10.1007/bf01236565 |jstor=20012239 |df=dmy-all}}&lt;/ref&gt;&lt;ref name=&quot;:0&quot;&gt;{{Cite journal |last=Galavotti |first=Maria Carla |date=1991-12-01 |title=The notion of subjective probability in the work of Ramsey and de Finetti |journal=Theoria |language=en |volume=57 |issue=3 |pages=239–259 |doi=10.1111/j.1755-2567.1991.tb00839.x |issn=1755-2567 |df=dmy-all}}&lt;/ref&gt; and [[Frank P. Ramsey]]&lt;ref name=&quot;:0&quot; /&gt;&lt;ref name=&quot;:1&quot;&gt;{{Cite book |title=Frank Ramsey: Truth and Success |last=Dokic |first=Jérôme |last2=Engel |first2=Pascal |publisher=Routledge |year=2003 |isbn=9781134445936}}&lt;/ref&gt; acknowledge their debts to [[pragmatic philosophy]], particularly (for Ramsey) to [[Charles Sanders Peirce|Charles S. Peirce]].&lt;ref name=&quot;:0&quot; /&gt;&lt;ref name=&quot;:1&quot; /&gt;

The &quot;Ramsey test&quot; for evaluating probability distributions is implementable in theory, and has kept experimental psychologists occupied for a half century.&lt;ref&gt;Davidson et al. (1957)&lt;/ref&gt;
This work demonstrates that Bayesian-probability propositions can be [[Falsifiability|falsified]], and so meet an empirical criterion of [[Charles Sanders Peirce|Charles S. Peirce]], whose work inspired Ramsey. (This [[falsifiability]]-criterion was popularized by [[Karl Popper]].&lt;ref&gt;{{cite encyclopedia |url=http://plato.stanford.edu/entries/popper/#ProDem |article=Karl Popper |title=Stanford Encyclopedia of Philosophy|first = Stephen |last =Thornton |date = 7 August 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite book |author=Popper, Karl |year=2002 |url=https://books.google.com/books?id=T76Zd20IYlgC&amp;printsec=frontcover&amp;dq=logic+of+scientific+discovery#v=onepage&amp;q=falsifiability |via=Google Books |title=The Logic of Scientific Discovery |edition=2nd |publisher=Routledge |ISBN=0-415-27843-0 |page=57 |orig-year=1959 |language=en}} (translation of 1935 original, in German).&lt;/ref&gt;)

Modern work on the experimental evaluation of personal probabilities uses the randomization, [[double blind|blinding]], and Boolean-decision procedures of the Peirce-Jastrow experiment.&lt;ref&gt;Peirce &amp; Jastrow (1885)
&lt;/ref&gt; Since individuals act according to different probability judgments, these agents' probabilities are &quot;personal&quot; (but amenable to objective study).

Personal probabilities are problematic for science and for some applications where decision-makers lack the knowledge or time to specify an informed probability-distribution (on which they are prepared to act). To meet the needs of science and of human limitations, Bayesian statisticians have developed &quot;objective&quot; methods for specifying prior probabilities.

Indeed, some Bayesians have argued the prior state of knowledge defines ''the'' (unique) prior probability-distribution for &quot;regular&quot; statistical problems; cf. [[well-posed problem]]s. Finding the right method for constructing such &quot;objective&quot; priors (for appropriate classes of regular problems) has been the quest of statistical theorists from Laplace to [[John Maynard Keynes]], [[Harold Jeffreys]], and [[Edwin Thompson Jaynes]]. These theorists and their successors have suggested several methods for constructing &quot;objective&quot; priors (Unfortunately, it is not clear how to assess the relative &quot;objectivity&quot; of the priors proposed under these methods):
* [[principle of maximum entropy|Maximum entropy]]
* [[Haar measure|Transformation group analysis]]
* [[José-Miguel Bernardo|Reference analysis]]

Each of these methods contributes useful priors for &quot;regular&quot; one-parameter problems, and each prior can handle some challenging [[statistical model]]s (with &quot;irregularity&quot; or several parameters). Each of these methods has been useful in Bayesian practice. Indeed, methods for constructing &quot;objective&quot; (alternatively, &quot;default&quot; or &quot;ignorance&quot;) priors have been developed by avowed subjective (or &quot;personal&quot;) Bayesians like [[James Berger (statistician)|James Berger]] ([[Duke University]]) and [[José-Miguel Bernardo]] ([[University of Valencia|Universitat de València]]), simply because such priors are needed for Bayesian practice, particularly in science.&lt;ref name=&quot;refa&quot;&gt;{{cite book |author=Bernardo, J. M. |year=2005 |url=http://www.uv.es/~bernardo/RefAna.pdf |article=Reference Analysis |title=Handbook of Statistics |volume=25 |editor1-first=D.K. |editor1-last=Dey |editor2-link=C. R. Rao |editor2-first=C. R. |editor2-last=Rao |location=Amsterdam |publisher=Elsevier |pages=17–90}}&lt;/ref&gt; The quest for &quot;the universal method for constructing priors&quot; continues to attract statistical theorists.&lt;ref name=&quot;refa&quot; /&gt;

Thus, the Bayesian statistician needs either to use informed priors (using relevant expertise or previous data) or to choose among the competing methods for constructing &quot;objective&quot; priors.

==See also==
{{Portal|Mathematics}}
* [[Bertrand paradox (probability)|Bertrand paradox]]&amp;mdash;a paradox in classical probability
* [[De Finetti's game]]&amp;mdash;a procedure for evaluating someone's subjective probability 
* [[QBism]]&amp;mdash;an [[interpretation of quantum mechanics]] based on subjective Bayesian probability
* [[Reference class problem]]
* ''[[An Essay towards solving a Problem in the Doctrine of Chances]]''
* [[Monty Hall problem]]

==References==
{{Reflist|30em}}

==Bibliography==
* {{cite book |author=Berger, James O. |author-link=James Berger (statistician) |title=Statistical Decision Theory and Bayesian Analysis |edition=Second |year=1985 |publisher=Springer-Verlag |series=Springer Series in Statistics |isbn=978-0-387-96098-2}}
* {{cite book |title=Bayesian Programming |year=2013 |publisher=CRC Press |isbn=9781439880326 |last1=Bessière |first1=Pierre |last2=Mazer |first2=E. |last3=Ahuacatzin |first3=J.-M. |last4=Mekhnacha |first4=K.}}
*{{cite book |title=Bayesian Theory |publisher=Wiley |year=1994 |isbn=978-0-471-49464-5 |authorlink1=José-Miguel Bernardo |last1=Bernardo |first1=José M. |author-link2=Adrian Smith (statistician) |last2=Smith |first2=Adrian F.M.}}
* {{cite book |last1=Bickel |first1=Peter J. |last2=Doksum |first2=Kjell A. |author-link1=Peter J. Bickel |series=Mathematical Statistics |volume=1 |title=Basic and selected topics |edition=Second |mr=443141 |year=2001 |orig-year=1976 |publisher=Pearson Prentice–Hall |isbn=978-0-13-850363-5 |ref=harv |quote=(updated printing, 2007, of Holden-Day, 1976)}}
* {{cite book |author-link1=Donald Davidson (philosopher) |first1=Donald |last1=Davidson |author-link2=Patrick Suppes |first2=Patrick |last2=Suppes |authorlink3=Sidney Siegel |first3=Sidney |last3=Siegel |title=Decision-Making: an Experimental Approach |publisher=[[Stanford University Press]] |year=1957}}
* {{cite journal |author=de Finetti, Bruno |year=1937 |title=La Prévision: ses lois logiques, ses sources subjectives |trans-title=Foresight: Its logical laws, its subjective sources|journal=Annales de l'Institut Henri Poincaré |url=http://www.numdam.org/item?id=AIHP_1937__7_1_1_0 |language=fr}}
* {{cite journal |author-link=Bruno de Finetti |author=de Finetti, Bruno |title=Probabilism: A critical essay on the theory of probability and on the value of science |orig-year=1931 |journal=Erkenntnis |volume=31 |date=September 1989}} (translation of de&amp;nbsp;Finetti, 1931)
* {{cite book |author=de Finetti, Bruno |author-link=Bruno de Finetti |article=Foresight: Its logical laws, its subjective sources |editor1=Kyburg, H.E. |editor2=Smokler, H.E. |title=Studies in Subjective Probability |location=New York, NY |publisher=Wiley |year=1964 |orig-year=1937 |language=en}} (translation of de&amp;nbsp;Finetti, 1937, above)
* {{cite book |last=de Finetti |first=Bruno |year=1974–1975 |title=Theory of Probability: A critical introductory treatment |translator1=Machi, A. |translator2=Smith, AFM |translator2-link=AFM Smith |orig-year=1970 |publisher=Wiley |ISBN=0-471-20141-3}}, {{ISBN|0-471-20142-1}}, two volumes.
* {{cite book |author-link=Morris DeGroot |author=DeGroot, Morris |year=2004 |title=Optimal Statistical Decisions |series=Wiley Classics Library |publisher=Wiley |orig-year=1970 |ISBN=0-471-68029-X}}.
* {{cite journal |doi=10.1086/288169 |title=Slightly more realistic personal probability |first=Ian |last=Hacking |author-link=Ian Hacking |journal=Philosophy of Science |volume=34 |issue=4 |date=December 1967 |pages=311–325 |jstor=186120}}  &lt;br /&gt;Partly reprinted in {{cite book |author1-link=Peter Gärdenfors |author1=Gärdenfors, Peter |author2=Sahlin, Nils-Eric |year=1988 |title=Decision, Probability, and Utility: Selected Readings |publisher=Cambridge University Press |ISBN=0-521-33658-9}}
* {{cite book |author1=Hajek, A. |author2=Hartmann, S. |year=2010 |contribution=Bayesian Epistemology |editor1=Dancy, J. |editor2=Sosa, E. |editor3=Steup, M. |orig-year=2001 |title=A Companion to Epistemology |publisher=Wiley |ISBN=1-4051-3900-5 |url=https://web.archive.org/web/20110728055439/http://stephanhartmann.org/HajekHartmann_BayesEpist.pdf}}
* {{cite book |last=Hald |first=Anders |author-link=Anders Hald |title=A History of Mathematical Statistics from 1750 to 1930 |year=1998 |publisher=Wiley |location=New York |isbn=978-0-471-17912-2}}
* {{cite book |author1=Hartmann, S. |author2=Sprenger, J. |year=2011 |contribution=Bayesian Epistemology |editor1=Bernecker, S. |editor2=Pritchard, D.  |title=Routledge Companion to Epistemology |publisher=Routledge |ISBN=978-0-415-96219-3 |url=https://web.archive.org/web/20110728055519/http://stephanhartmann.org/HartmannSprenger_BayesEpis.pdf}}
* {{springer |title=Bayesian approach to statistical problems |id=p/b015390}}
* {{cite book |title=Scientific Reasoning: The Bayesian approach  |author-link1=Colin Howson |last1=Howson |first1=C. |last2=Urbach |first2=P. |publisher=[[Open Court Publishing Company]] |year=2005 |edition=3rd |isbn=978-0-8126-9578-6}}
* {{cite book |author-link=Edwin Thompson Jaynes |author=Jaynes, E.T. |year=2003 |title=Probability Theory: The logic of science |publisher=C. University Press |ISBN=978-0-521-59271-0}} ({{cite web |url=http://www-biba.inrialpes.fr/Jaynes/prob.html |title=Link to fragmentary edition of March 1996}}
* {{cite book |author=McGrayne, S.B. |year=2011 |title=The Theory that would not Die: How Bayes' rule cracked the Enigma code, hunted down Russian submarines, and emerged triumphant from two centuries of controversy |url=https://archive.org/details/theorythatwouldn0000mcgr |url-access=registration |location=New Haven, CT |publisher=Yale University Press |ISBN=9780300169690 |OCLC=670481486}}
*{{cite book |author=Morgenstern, Oskar |author-link=Oskar Morgenstern |year=1978 |publisher=New York University Press |chapter=Some Reflections on [[Expected utility|Utility]] |pages=65–70 |title=Selected Economic Writings of Oskar Morgenstern |editor=Schotter, Andrew |isbn=978-0-8147-7771-8}}
* {{cite journal |author=Peirce, C.S. |author-link=Charles Sanders Peirce |author2=Jastrow J. |author2-link=Joseph Jastrow |last-author-amp=yes |year=1885 |title=On Small Differences in Sensation |journal=Memoirs of the National Academy of Sciences |volume=3 |pages=73–83 |url=http://psychclassics.yorku.ca/Peirce/small-diffs.htm}}
* {{cite book |author=Pfanzagl, J |year=1967 |publisher=Princeton University Press |chapter=Subjective Probability Derived from the Morgenstern-von Neumann Utility Theory |pages=[https://archive.org/details/essaysinmathemat0000shub/page/237 237–251] |title=Essays in Mathematical Economics In Honor of Oskar Morgenstern |url=https://archive.org/details/essaysinmathemat0000shub |url-access=registration |editor=Martin Shubik |editor-link=Martin Shubik}}
* {{cite book|author=Pfanzagl, J. |author2=Baumann, V. |author3=Huber, H. |last-author-amp=yes |year=1968 |publisher=Wiley |chapter=Events, Utility and Subjective Probability |pages=195–220 |title=Theory of Measurement}}
* {{cite book |author-link=Frank P. Ramsey |author=Ramsey, Frank Plumpton |orig-year=1931 |chapter=Chapter VII: Truth and Probability |title=The Foundations of Mathematics and other Logical Essays |year=2001 |publisher=Routledge |ISBN=0-415-22546-9}} {{cite web |url=https://web.archive.org/web/20080227205205/http://cepa.newschool.edu/het//texts/ramsey/ramsess.pdf |title=Chapter VII: Truth and Probability}}
* {{cite book |author=Stigler, S.M. |authorlink=Stephen Stigler |year=1990 |title=The History of Statistics: The Measurement of Uncertainty before 1900 |publisher=Belknap Press; Harvard University Press |isbn=978-0-674-40341-3}}
* {{cite book |author=Stigler, S.M. |year=1999 |title=Statistics on the Table: The history of statistical concepts and methods |publisher=Harvard University Press |ISBN=0-674-83601-4}}
* {{cite book |author=Stone, J.V. |year=2013 |title=Bayes’ Rule: A tutorial introduction to Bayesian analysis |publisher=Sebtel Press |location=England}} {{cite web |url=http://jim-stone.staff.shef.ac.uk/BookBayes2012/BayesRuleBookMain.html |title=Chapter 1 of ''Bayes’ Rule''.}}
* {{cite book |author=Winkler, R.L. |title=Introduction to Bayesian Inference and Decision |publisher=Probabilistic |year=2003 |isbn=978-0-9647938-4-2 |edition=2nd   |quote=Updated classic textbook. Bayesian theory clearly presented}}

{{DEFAULTSORT:Bayesian Probability}}
[[Category:Bayesian statistics|Probability]]
[[Category:Justification]]
[[Category:Probability interpretations]]
[[Category:Philosophy of mathematics]]
[[Category:Philosophy of science]]</text>
      <sha1>jhwcw7kjbtgoc63ozj4g1s05r5yzwv7</sha1>
    </revision>
  </page>
