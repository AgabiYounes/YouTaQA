  <page>
    <title>Audio signal processing</title>
    <ns>0</ns>
    <id>2322</id>
    <revision>
      <id>943348641</id>
      <parentid>942144104</parentid>
      <timestamp>2020-03-01T10:48:09Z</timestamp>
      <contributor>
        <ip>92.8.204.165</ip>
      </contributor>
      <comment>/* Further reading */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">{{Other uses|Audio effect (disambiguation){{!}}Audio effect}}

'''Audio signal processing''' is a subfield of [[signal processing]] that is concerned with the electronic manipulation of [[audio signal]]s. Audio signals are electronic representations of [[sound wave]]s—[[longitudinal wave]]s which travel through air, consisting of compressions and rarefactions. The energy contained in audio signals is typically measured in [[decibel]]s.  As audio signals may be represented in either [[Digital signal (signal processing)|digital]] or [[analog signal|analog]] format, processing may occur in either domain.  Analog processors operate directly on the electrical signal, while digital processors operate mathematically on its digital representation.

== History ==
The motivation for audio signal processing began at the beginning of the 20th century with inventions like the [[telephone]], [[phonograph]], and [[radio]] that allowed for the transmission and storage of audio signals. Audio processing was necessary for early [[radio broadcasting]], as there were many problems with [[studio-to-transmitter link]]s.&lt;ref&gt;{{cite book|last=Atti|first=Andreas Spanias, Ted Painter, Venkatraman|title=Audio signal processing and coding|year=2006|publisher=John Wiley &amp; Sons|location=Hoboken, NJ|isbn=0-471-79147-4|pages=464|url=https://books.google.com/books?id=Z_z-OQbadPIC|edition=[Online-Ausg.]}}&lt;/ref&gt; The theory of signal processing and its application to audio was largely developed at [[Bell Labs]] in the mid 20th century. [[Claude Shannon]] and [[Harry Nyquist]]'s early work on [[communication theory]], [[Nyquist–Shannon sampling theorem|sampling theory]], and [[Pulse-code modulation]] laid the foundations for the field. In 1957, [[Max Mathews]] became the first person to synthesize audio from a computer, giving birth to [[computer music]].

== Analog signals ==

{{Main|Analog signal processing}}
An analog audio signal is a continuous signal represented by an electrical voltage or current that is “analogous” to the sound waves in the air. Analog signal processing then involves physically altering the continuous signal by changing the voltage or current or charge via [[electrical circuits]].

Historically, before the advent of widespread [[digital technology]], analog was the only method by which to manipulate a signal. Since that time, as computers and software have become more capable and affordable and digital signal processing has become the method of choice. However, in music applications, analog technology is often still desirable as it often produces [[nonlinear]] responses that are difficult to replicate with digital filters.

== Digital signals ==

{{Main|Digital signal processing}}
A digital representation expresses the audio waveform as a sequence of symbols, usually [[Binary numeral system|binary numbers]].  This permits signal processing using [[digital circuits]] such as [[digital signal processor]]s, [[microprocessor]]s and general-purpose [[computer]]s.  Most modern audio systems use a digital approach as the techniques of digital signal processing are much more powerful and efficient than analog domain signal processing.&lt;ref&gt;{{Cite book |title=Digital Audio Signal Processing |first=Udo |last=Zölzer |publisher=John Wiley and Sons |year=1997 |ISBN=0-471-97226-6}}&lt;/ref&gt;

== Application areas ==

Processing methods and application areas include [[audio storage|storage]], [[audio data compression|data compression]], [[music information retrieval]], [[speech processing]], [[acoustic location|localization]], [[detection theory|acoustic detection]], [[transmission (telecom)|transmission]], [[noise cancellation]], [[acoustic fingerprint|acoustic fingerprinting]], [[sound recognition]], [[synthesizer|synthesis]], and enhancement (e.g. [[Equalization (audio)|equalization]], [[audio filter|filtering]], [[audio level compression|level compression]], [[Echo (phenomenon)|echo]] and [[reverb]] removal or addition, etc.).

=== Audio broadcasting ===
{{see also | Broadcasting}}
Audio signal processing is used when broadcasting audio signals in order to enhance their fidelity or optimize for bandwidth or latency. In this domain, the most important audio processing takes place just before the transmitter. The audio processor here must prevent or minimize [[overmodulation]], compensate for non-linear transmitters (a potential issue with [[medium wave]] and [[shortwave]] broadcasting), and adjust overall [[loudness]] to desired level.
=== Active noise control ===

[[Active noise control]] is a technique designed to reduce unwanted sound. By creating a signal that is identical to the unwanted noise but with the opposite polarity, the two signals cancel out due to [[destructive interference]].

=== Audio synthesis ===
{{see also|Synthesizer}}

Audio synthesis is the electronic generation of audio signals. A musical instrument that accomplishes this is called a synthesizer. Synthesizers can either [[Physical modelling synthesis|imitate sounds]] or generate new ones. Audio synthesis is also used to generate human [[speech]] using [[speech synthesis]].

=== Audio effects ===

'''Audio effects''' are systems designed to alter how an audio signal sounds. Unprocessed audio is metaphorically referred to as ''dry'', while processed audio is referred to as ''wet''.&lt;ref&gt;Hodgson, Jay (2010). ''Understanding Records'', p.95. {{ISBN|978-1-4411-5607-5}}.&lt;/ref&gt;

* ''[[Delay (audio effect)|delay]]'' or echo - To simulate the effect of reverberation in a large hall or cavern, one or several delayed signals are added to the original signal. To be perceived as echo, the delay has to be of order 35 milliseconds or above.  Short of actually playing a sound in the desired environment, the effect of echo can be implemented using either [[Digital data|digital]] or [[analog (signal)|analog]] methods.  Analog echo effects are implemented using tape delays or [[bucket-brigade device]]s.  When large numbers of delayed signals are mixed a [[reverberation]] effect is produced; The resulting sound has the effect of being presented in a large room.
* ''[[flanging|flanger]]'' - to create an unusual sound, a delayed signal is added to the original signal with a continuously variable delay (usually smaller than 10 ms).  This effect is now done electronically using [[digital signal processing|DSP]], but originally the effect was created by playing the same recording on two synchronized tape players, and then mixing the signals together.  As long as the machines were synchronized, the mix would sound more-or-less normal, but if the operator placed his finger on the flange of one of the players (hence &quot;flanger&quot;), that machine would slow down and its signal would fall out-of-phase with its partner, producing a phasing [[comb filter]] effect.  Once the operator took his finger off, the player would speed up until it was back in phase with the master, and as this happened, the phasing effect would appear to slide up the frequency spectrum.  This phasing up-and-down the register can be performed rhythmically.
* ''[[phaser (effect)|phaser]]'' - another way of creating an unusual sound; the signal is split, a portion is [[audio filter|filtered]] with a variable [[all-pass filter]] to produce a phase-shift, and then the unfiltered and filtered signals are mixed to produce a comb filter. The phaser effect was originally a simpler implementation of the flanger effect since delays were difficult to implement with analog equipment.
* ''[[chorus effect|chorus]]'' - a delayed version of the signal is added to the original signal. The delay has to be short in order not to be perceived as echo, but above 5 ms to be audible.  If the delay is too short, it will destructively interfere with the un-delayed signal and create a [[flanging]] effect.  Often, the delayed signals will be slightly pitch shifted to more realistically convey the effect of multiple voices.
* ''[[equalization (audio)|equalization]]'' - [[frequency response]] is adjusted using [[audio filter]](s) to produce desired spectral characteristics. Frequency ranges can be emphasized or attenuated using [[Low-pass filter|low-pass]], [[High-pass filter|high-pass]], [[Band-pass filter|band-pass]] or [[Band-stop filter|band-stop]] filters.  Moderate use of equalization can be used to fine-tune the tonal quality of a recording; extreme use of equalization, such as heavily cutting a certain frequency can create more unusual effects. Band-pass filtering of voice can simulate the effect of a telephone because telephones use band-pass filters.
* ''[[Overdrive (music)|overdrive]]'' effects can be used to produce distorted sounds, and increase [[loudness]]. The most basic overdrive effect involves [[Clipping (audio)|clipping]] the signal when its [[absolute value]] exceeds a certain threshold.
* ''[[audio timescale-pitch modification|timescale-pitch modification]]'' - this effect shifts a signal up or down in pitch. For example, a signal may be shifted an octave up or down. Blending the original signal with shifted duplicate(s) can create [[harmonization]].  Another application of pitch shifting is [[pitch correction]] where a musical signal is adjusted to improve [[Intonation (music)|intonation]]. The complement of pitch shift is timescale modification, that is, the process of changing the speed of an audio signal without affecting its pitch.
* ''[[resonators]]'' - emphasize harmonic frequency content on specified frequencies. These may be created from [[parametric equation]] or from delay-based comb-filters.&lt;!--[[User:Kvng/RTH]]--&gt;
* ''[[robotic voice effects]]'' are used to make an actor's voice sound like a synthesized human voice.
* ''[[modulation]]'' - to change the frequency or amplitude of a carrier signal in relation to a predefined signal. [[Ring modulation]] is an effect made famous by [[Doctor Who]]'s [[Dalek]]s and commonly used throughout sci-fi.
* ''[[Dynamic range compression|compression]]'' - the reduction of the dynamic range of a sound to avoid unintentional fluctuation in the dynamics.  Level compression is not to be confused with [[audio data compression]], where the amount of data is reduced without affecting the amplitude of the sound it represents.
* ''[[3D audio effect]]s'' - place sounds outside the stereo basis
* ''[[reverse echo]]'' - a swelling effect created by reversing an audio signal and recording echo and/or delay while the signal runs in reverse. When played back forward the last echos are heard before the effected sound creating a rush like swell preceding and during playback. [[Jimmy Page]] of [[Led Zeppelin]] used this effect in the bridge of &quot;[[Whole Lotta Love]]&quot;.&lt;ref&gt;{{cite web |url=http://www.songfacts.com/detail.php?id=308 |title=WHOLE LOTTA LOVE by LED ZEPPELIN |access-date=5 January 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.led-zeppelin.org/assorted-info/53-pages-studio-tricks-iii-backwards-echo |title=Page's Studio Tricks III (Backwards echo) |last=O'Neil |first=Bill |access-date=5 January 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://audioschoolonline.blogspot.in/2012/11/the-history-of-reverse-reverb.html |title=The History of Reverse Reverb |last=Audrey |access-date=5 January 2018}}&lt;/ref&gt;
* ''[[wave field synthesis]]'' - a spatial audio rendering technique for the creation of virtual acoustic environments
* [[De-essing|De-esser]] - Some sounds in recorded speech such as &quot;s&quot;, &quot;z&quot;, &quot;ch&quot;, &quot;j&quot; and &quot;sh&quot; can be louder than vowels. This is known as [[Sibilant|sibilance]] and there are several time and frequency based algorithms that can reduce sibilance or de-ess the sound. Time domain based approaches, such as band pass filters, are more suited to real time applications such as live radio due to less constraint on [[Digital signal processor]]. Playback or offline applications incorporate [[Fast_Fourier_transform|Fast Fourier Transform]] (FFT) based methods.

== See also ==
* [[Sound card]]
* [[Sound effect]]

== References ==
{{Reflist}}

== Further reading ==
*{{Cite book | last = Rocchesso | first = Davide | authorlink = | coauthors = | title = Introduction to Sound Processing | publisher = | date = March 20, 2003| pages = | url = http://dsp-book.narod.ru/spv.pdf | doi = | isbn = }}
*{{Cite journal |last1=Wilmering |first1=Thomas |last2=Moffat |first2=David |last3=Milo |first3=Alessia |last4=Sandler |first4=Mark B. |title=A History of Audio Effects |journal=Applied Sciences |date=2020 |volume=10 |issue=3 |page=791 |doi=10.3390/app10030791 |url=https://www.mdpi.com/2076-3417/10/3/791}}
{{Audio broadcasting}}
{{Music production}}
{{DEFAULTSORT:Audio Signal Processing}}
[[Category:Audio electronics]]
[[Category:Signal processing]]</text>
      <sha1>gnz38n1xoxzowtv6x8czux53dlg2h8p</sha1>
    </revision>
  </page>
