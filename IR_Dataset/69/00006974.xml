  <page>
    <title>Computer music</title>
    <ns>0</ns>
    <id>6974</id>
    <revision>
      <id>938308319</id>
      <parentid>938125441</parentid>
      <timestamp>2020-01-30T11:26:06Z</timestamp>
      <contributor>
        <username>Sirfurboy</username>
        <id>599562</id>
      </contributor>
      <comment>See [[Category talk:Media synthesis]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">{{Redirect|Computer Music|the magazine|Computer Music (magazine)}}
{{Use dmy dates|date=December 2013}}
{{more citations needed|date=March 2017}}
'''Computer music''' is the application of [[computing technology]] in [[musical composition|music composition]], to help human [[composer]]s create new music or to have computers independently create music, such as with [[algorithmic composition]] programs. It includes the theory and application of new and existing computer [[software]] technologies and basic aspects of music, such as [[sound synthesis]], [[digital signal processing]], [[sound design]], sonic diffusion, [[acoustics]], and [[psychoacoustics]]. The field of computer music can trace its roots back to the origins of [[electronic music]], and the very first experiments and innovations with electronic instruments at the turn of the 20th century.

In the 2000s, with the widespread availability of relatively affordable [[personal computing|home computers]] that have a fast processing speed, and the growth of [[home recording]] using [[digital audio recording]] systems ranging from [[GarageBand]] to [[Pro Tools]], the term is sometimes used to describe music that has been created using digital technology.

==History==
{{See also|Computer music programming languages}}
[[image:CSIRAC-Pano,-Melb.-Museum,-12.8.2008.jpg|thumb|left|300x300px|[[CSIRAC]], Australia's first digital computer, as displayed at the [[Melbourne Museum]]]]
Much of the work on computer music has drawn on the relationship between [[music and mathematics]], a relationship which has been noted since the [[Ancient Greece|Ancient Greeks]] described the &quot;[[harmony of the spheres]]&quot;.

Musical melodies were first generated by the computer originally named the CSIR Mark 1 (later renamed [[CSIRAC]]) in Australia in 1950. There were newspaper reports from America and England (early and recently) that computers may have played music earlier, but thorough research has debunked these stories as there is no evidence to support the newspaper reports (some of which were obviously speculative). Research has shown that people ''speculated'' about computers playing music, possibly because computers would make noises,&lt;ref name=&quot;Algorhythmic Listening 1949-1962 Auditory Practices of Early Mainframe Computing&quot;&gt;{{cite web |title=Algorhythmic Listening 1949–1962 Auditory Practices of Early Mainframe Computing |url=http://www.computing-conference.ugent.be/file/12 |work=[[AISB/IACAP World Congress 2012]] |accessdate=18 October 2017 |archive-url=https://web.archive.org/web/20171107072033/http://www.computing-conference.ugent.be/file/12 |archive-date=7 November 2017 |url-status=dead }}&lt;/ref&gt; but there is no evidence that they actually did it.&lt;ref name=&quot;Early Computer Music Experiments in Australia, England and the USA&quot;&gt;{{cite journal|title=MuSA 2017 – Early Computer Music Experiments in Australia, England and the USA |url=https://www.academia.edu/34234640 |journal=[[MuSA Conference]] |accessdate=18 October 2017 |date=9 July 2017|last1=Doornbusch |first1=Paul }}&lt;/ref&gt;&lt;ref name=&quot;Doornbusch&quot;&gt;{{cite journal|last=Doornbusch|first=Paul|title= Early Computer Music Experiments in Australia and England |journal=[[Organised Sound]]|year=2017|volume=22|issue=2|pages=297–307 [11]|publisher=[[Cambridge University Press]]|doi=10.1017/S1355771817000206}}&lt;/ref&gt;

The world's first computer to play music was the CSIR Mark 1 (later named [[CSIRAC]]), which was designed and built by [[Trevor Pearcey]] and Maston Beard from the late 1940s. Mathematician Geoff Hill programmed the CSIR Mark 1 to play popular musical melodies from the very early 1950s. In 1950 the CSIR Mark 1 was used to play music, the first known use of a digital computer for the purpose. The music was never recorded, but it has been accurately reconstructed.&lt;ref name=&quot;beebmus&quot;&gt;{{cite news|title=Oldest computer music unveiled |url=http://news.bbc.co.uk/1/hi/technology/7458479.stm| date=2008-06-17|accessdate=2008-06-18|work=[[BBC News Online]]|last=Fildes|first=Jonathan }}&lt;/ref&gt;
&lt;ref name=&quot;:0&quot;&gt;{{Cite journal|last=Doornbusch|first=Paul|date=March 2004|title=Computer Sound Synthesis in 1951: The Music of CSIRAC|journal=Computer Music Journal|language=en|volume=28|issue=1|pages=11–12|doi=10.1162/014892604322970616|issn=0148-9267}}&lt;/ref&gt; In 1951 it publicly played the &quot;[[Colonel Bogey March]]&quot;&lt;ref&gt;{{cite web| last = Doornbusch | first = Paul| title = The Music of CSIRAC | publisher = Melbourne School of Engineering, Department of Computer Science and Software Engineering| url = http://www.csse.unimelb.edu.au/dept/about/csirac/music/introduction.html |archiveurl=https://web.archive.org/web/20120118000725/http://www.csse.unimelb.edu.au/dept/about/csirac/music/introduction.html |archivedate=18 January 2012}}&lt;/ref&gt; of which only the reconstruction exists. However, the CSIR Mark 1 played standard repertoire and was not used to extend musical thinking or composition practice, as [[Max Mathews]] did, which is current computer-music practice.

The first music to be performed in England was a performance of the [[God Save the King|British National Anthem]] that was programmed by [[Christopher Strachey]] on the [[Ferranti Mark 1]], late in 1951. Later that year, short extracts of three pieces were recorded there by a [[BBC]] outside broadcasting unit: the National Anthem, &quot;[[Ba, Ba Black Sheep]], and &quot;[[In the Mood]]&quot; and this is recognised as the earliest recording of a computer to play music as the [[CSIRAC]] music was never recorded. This recording can be heard at the [http://curation.cs.manchester.ac.uk/digital60/www.digital60.org/media/index.html this Manchester University site]. Researchers at the [[University of Canterbury]], Christchurch declicked and restored this recording in 2016 and the results may be heard on [[SoundCloud]].&lt;ref name=&quot;Turing&quot;&gt;{{cite web|title=First recording of computer-generated music – created by Alan Turing – restored |url=https://www.theguardian.com/science/2016/sep/26/first-recording-computer-generated-music-created-alan-turing-restored-enigma-code |work=[[The Guardian]] |accessdate=28 August 2017 |date=26 September 2016}}&lt;/ref&gt;&lt;ref name=&quot;BL-2016-09&quot;&gt;{{cite web|title=Restoring the first recording of computer music – Sound and vision blog|url=http://blogs.bl.uk/sound-and-vision/2016/09/restoring-the-first-recording-of-computer-music.html|publisher=[[British Library]]|accessdate=28 August 2017|language=en|date=13 September 2016}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last=Fildes |first=Jonathan |title='Oldest' computer music unveiled |url=http://news.bbc.co.uk/2/hi/technology/7458479.stm |journal=BBC News |date=June 17, 2008 |accessdate=4 December 2013}}&lt;/ref&gt;

Two further major 1950s developments were the origins of digital sound synthesis by computer, and of [[algorithmic composition]] programs beyond rote playback. Max Mathews at Bell Laboratories developed the influential [[MUSIC-N|MUSIC I]] program and its descendants, further popularising computer music through a 1963 article in ''Science''.&lt;ref&gt;{{cite book |last=Bogdanov |first=Vladimir |date=2001 |title=All Music Guide to Electronica: The Definitive Guide to Electronic Music | publisher=Backbeat Books |page=320 |url=https://books.google.com/?id=GJNXLSBlL7IC&amp;printsec=frontcover&amp;dq=All+Music+Guide+to+Electronica:+The+Definitive+Guide+to+Electronic+Music#v=onepage&amp;q=All%20Music%20Guide%20to%20Electronica%3A%20The%20Definitive%20Guide%20to%20Electronic%20Music&amp;f=false |accessdate=4 December 2013|isbn=9780879306281 }}&lt;/ref&gt; Amongst other pioneers, the musical chemists [[Lejaren Hiller]] and Leonard Isaacson worked on a series of algorithmic composition experiments from 1956-9, manifested in the 1957 premiere of the ''Illiac Suite'' for string quartet.&lt;ref&gt;Lejaren Hiller and Leonard Isaacson, ''Experimental Music: Composition with an Electronic Computer'' (New York: McGraw-Hill, 1959; reprinted Westport, Conn.: Greenwood Press, 1979). {{ISBN|0-313-22158-8}}. {{Page needed|date=November 2010}}&lt;/ref&gt;

In [[Japan]], experiments in computer music date back to 1962, when [[Keio University]] professor Sekine and [[Toshiba]] engineer Hayashi experimented with the {{ill|TOSBAC|jp|vertical-align=sup}} computer. This resulted in a piece entitled ''TOSBAC Suite'', influenced by the ''Illiac Suite''. Later Japanese computer music compositions include a piece by Kenjiro Ezaki presented during [[Osaka Expo '70]] and &quot;Panoramic Sonore&quot; (1974) by music critic Akimichi Takeda. Ezaki also published an article called &quot;Contemporary Music and Computers&quot; in 1970. Since then, Japanese research in computer music has largely been carried out for commercial purposes in [[popular music]], though some of the more serious Japanese musicians used large computer systems such as the ''[[Fairlight (company)|Fairlight]]'' in the 1970s.&lt;ref name=&quot;shimazu104&quot;&gt;{{cite journal|last=Shimazu|first=Takehito|title=The History of Electronic and Computer Music in Japan: Significant Composers and Their Works|journal=[[Leonardo Music Journal]]|year=1994|volume=4|pages=102–106 [104]|url=https://www.scribd.com/doc/93116556/The-History-of-Electronic-and-Experimental-Music-in-Japan|accessdate=9 July 2012|publisher=[[MIT Press]]|doi=10.2307/1513190|jstor=1513190}}&lt;/ref&gt;
[[Image:Yamaha GS-1 FM Synthesizer Programming Computer.jpg|thumb|200px|The programming computer for Yamaha's first FM synthesizer GS1. [[CCRMA]], Stanford University]]

Early computer-music programs typically did not run in [[Real-time computing|real time]], although the first experiments on [[CSIRAC]] and the [[Ferranti Mark 1]] did operate in [[Real-time computing|real time]]. From the late 1950s, with increasingly sophisticated programming,  programs would run for hours or days, on multimillion-dollar computers, to generate a few minutes of music.&lt;ref&gt;{{cite web|last=Cattermole|first=Tannith|title=Farseeing inventor pioneered computer music|url=http://www.gizmag.com/computer-music-pioneer-max-mathews/18530/|publisher=Gizmag |accessdate=28 October 2011|date=May 9, 2011}}&lt;br&gt;&quot;In 1957 the MUSIC program allowed an IBM 704 mainframe computer to play a 17-second composition by Mathews. Back then computers were ponderous, so synthesis would take an hour.&quot;&lt;/ref&gt;&lt;ref name=Sci11-63MaxMat&gt;{{cite journal|last=Mathews|first=Max|title=The Digital Computer as a Musical Instrument|journal=Science|date=1 November 1963|volume=142|issue=3592|pages=553–557|doi=10.1126/science.142.3592.553|pmid=17738556|bibcode=1963Sci...142..553M}}&lt;br&gt;&quot;The generation of sound signals requires very high sampling rates.... A high speed machine such as the I.B.M. 7090 ... can compute only about 5000 numbers per second ... when generating a reasonably complex sound.&quot;&lt;/ref&gt; One way around this was to use a 'hybrid system' of digital control of an [[analog synthesiser]] and early examples of this were Max Mathews' GROOVE system (1969) and also MUSYS by [[Peter Zinovieff]] (1969). In the late 1970s these systems became commercialised, notably by systems like the [[Roland MC-8 Microcomposer]], where a [[microprocessor]]-based system controls an [[analog synthesizer]], released in 1978.&lt;ref name=&quot;shimazu104&quot;/&gt; [[John Chowning]]'s work on [[FM synthesis]] from the 1960s to the 1970s allowed much more efficient digital synthesis,&lt;ref&gt;{{cite book|last=Dean|first=R. T.|title=The Oxford handbook of computer music|year=2009|publisher=Oxford University Press|isbn=978-0-19-533161-5|page=20}}&lt;/ref&gt; eventually leading to the development of the affordable FM synthesis-based [[Yamaha DX7]] [[digital synthesizer]], released in 1983.&lt;ref name=&quot;dean1&quot;&gt;{{cite book|last=Dean|first=R. T.|title=The Oxford handbook of computer music|year=2009|publisher=Oxford University Press|isbn=978-0-19-533161-5|page=1}}&lt;/ref&gt; In addition to the Yamaha DX7, the advent of inexpensive digital [[Microprocessor|chips]] and [[microcomputer]]s opened the door to real-time generation of computer music.&lt;ref name=&quot;dean1&quot;/&gt; In the 1980s, Japanese [[personal computer]]s such as the [[NEC PC-8801|NEC PC-88]] came installed with FM synthesis [[sound chip]]s and featured [[audio programming language]]s such as [[Music Macro Language]] (MML) and [[MIDI]] interfaces, which were most often used to produce [[video game music]], or [[chiptune]]s.&lt;ref name=&quot;shimazu104&quot;/&gt; By the early 1990s, the performance of microprocessor-based computers reached the point that real-time generation of computer music using more general programs and algorithms became possible.&lt;ref name=RTDean2009&gt;{{cite book|last=Dean|first=R. T.|title=The Oxford handbook of computer music|year=2009|publisher=Oxford University Press|isbn=978-0-19-533161-5|pages=4–5}}&lt;br&gt;&quot;... by the 90s ... digital sound manipulation (using MSP or many other platforms) became widespread, fluent and stable.&quot;&lt;/ref&gt;
&lt;blockquote&gt;Interesting sounds must have a fluidity and changeability that allows them to remain fresh to the ear. In computer music this subtle ingredient is bought at a high computational cost, both in terms of the number of items requiring detail in a score and in the amount of interpretive work the instruments must produce to realize this detail in sound.&lt;ref name=CRMM-Loy&gt;{{cite book |editor-last=Roads |editor-first=Curtis |title=The Music Machine: Selected Readings from Computer Music Journal |year=1992 |publisher=MIT Press |isbn=978-0-262-68078-3 |page=344 |author=Loy, D. Gareth |authorlink=Gareth Loy |chapter=Notes on the implementation of MUSBOX...}}&lt;/ref&gt; &lt;/blockquote&gt;

==Advances==
Advances in computing power and software for manipulation of digital media have dramatically affected the way computer music is generated and performed. Current-generation micro-computers are powerful enough to perform very sophisticated audio synthesis using a wide variety of algorithms and approaches. Computer music systems and approaches are now ubiquitous, and so firmly embedded in the process of creating music that we hardly give them a second thought: computer-based synthesizers, digital mixers, and effects units have become so commonplace that use of digital rather than analog technology to create and record music is the norm, rather than the exception.&lt;ref&gt;{{cite book |last=Doornbusch |first=Paul |editor-last=Dean |editor-first=R. T. |title= The Oxford handbook of computer music |publisher= Oxford University Press | year=2009 |pages=44–80 |chapter=Chapter 3: Early Hardware and Early Ideas in Computer Music: Their Development and Their Current Forms |doi=10.1093/oxfordhb/9780199792030.013.0003 |isbn=978-0-19-533161-5}}&lt;/ref&gt;

==Research==
Despite the ubiquity of computer music in contemporary culture, there is considerable activity in the field of computer music,{{clarify|date=November 2019|reason=Would a lot of activity be more likely if it were rare in contemporary culture?}} as researchers continue to pursue new and interesting computer-based synthesis, composition, and performance approaches. Throughout the world there are many organizations and institutions dedicated to the area of computer and electronic music study and research, including the [[International Computer Music Association|ICMA]] (International Computer Music Association), C4DM (Centre for Digital Music), [[IRCAM]], GRAME, [[SEAMUS]] (Society for Electro Acoustic Music in the United States), [[Canadian Electroacoustic Community|CEC]] (Canadian Electroacoustic Community), and a great number of institutions of higher learning around the world.

===Music composed and performed by computers===
{{Main|Algorithmic composition}}
{{See also|Generative music|Evolutionary music|Genetic algorithm}}
Later, composers such as [[Gottfried Michael Koenig]] and [[Iannis Xenakis]] had computers generate the sounds of the composition as well as the score. Koenig produced [[algorithmic composition]] programs which were a generalisation of his own [[serial composition]] practice. This is not exactly similar to Xenakis' work as he used mathematical abstractions and examined how far he could explore these musically. Koenig's software translated the calculation of mathematical equations into codes which represented musical notation. This could be converted into musical notation by hand and then performed by human players. His programs Project 1 and Project 2 are examples of this kind of software. Later, he extended the same kind of principles into the realm of synthesis, enabling the computer to produce the sound directly. SSP is an example of a program which performs this kind of function. All of these programs were produced by Koenig at the [[Institute of Sonology]] in [[Utrecht]] in the 1970s.&lt;ref name=&quot;Berg, P.&quot;&gt;{{cite journal|last=Berg|first=P|title= Abstracting the future: The Search for Musical Constructs |journal=[[Computer Music Journal]]|year=1996|volume=20|issue=3|pages=24–27 [11]|publisher=[[MIT Press]]|doi=10.2307/3680818|jstor=3680818}}&lt;/ref&gt;

===Computer-generated scores for performance by human players===
Computers have also been used in an attempt to imitate the music of great composers of the past, such as [[Wolfgang Amadeus Mozart|Mozart]]. A present exponent of this technique is [[David Cope]]. He wrote computer programs that analyse works of other composers to produce new works in a similar style. He has used this program to great effect with composers such as Bach and Mozart (his program ''Experiments in Musical Intelligence'' is famous for creating &quot;Mozart's 42nd Symphony&quot;), and also within his own pieces, combining his own creations with that of the computer.&lt;ref&gt;{{Cite book|url=https://books.google.com/?id=lrQwBwAAQBAJ&amp;pg=PA281&amp;lpg=PA281&amp;dq=He+has+used+this+program+to+great+effect+with+composers+such+as+Bach+and+Mozart+(his+program+Experiments+in+Musical+Intelligence+is+famous+for+creating+%22Mozart's+42nd+Symphony%22),+and+also+within+his+own+pieces,+combining+his+own+creations+with+that+of+the+computer.#v=onepage&amp;q=He%20has%20used%20this%20program%20to%20great%20effect%20with%20composers%20such%20as%20Bach%20and%20Mozart%20(his%20program%20Experiments%20in%20Musical%20Intelligence%20is%20famous%20for%20creating%20%22Mozart's%2042nd%20Symphony%22),%20and%20also%20within%20his%20own%20pieces,%20combining%20his%20own%20creations%20with%20that%20of%20the%20computer.&amp;f=false|title=The Future of Post-Human Performing Arts: A Preface to a New Theory of the Body and its Presence|last=Baofu|first=Peter|date=2013-01-03|publisher=Cambridge Scholars Publishing|isbn=9781443844857|language=en}}&lt;/ref&gt;

[[Melomics]], a research project from the [[University of Málaga]] (Spain), developed a computer composition cluster named [[Iamus (computer)|Iamus]], which composes complex, multi-instrument pieces for editing and performance. Since its inception, [[Iamus (computer)|Iamus]] has composed a full album in 2012, appropriately named [[Iamus (album)|Iamus]], which [[New Scientist]] described as &quot;The first major work composed by a computer and performed by a full orchestra.&quot;&lt;ref&gt;{{cite journal |title=Computer composer honours Turing's centenary| journal=New Scientist |date=5 July 2012 |url=https://www.newscientist.com/article/mg21528724.300-computer-composer-honours-turings-centenary.html}}&lt;/ref&gt; The group has also developed an [[API]] for developers to utilize the technology, and makes its music available on its website.

==={{anchor|Computer-Aided Algorithmic Composition}}Computer-aided algorithmic composition===
[[Image:GenSystemVenn.png|thumb|right|Diagram illustrating the position of CAAC in relation to other [[Generative music]] Systems]]Computer-aided algorithmic composition (CAAC, pronounced &quot;sea-ack&quot;) is the implementation and use of [[algorithmic composition]] techniques in software. This label is derived from the combination of two labels, each too vague for continued use. The label ''computer-aided composition'' lacks the specificity of using generative algorithms. Music produced with notation or sequencing software could easily be considered computer-aided composition. The label ''algorithmic composition'' is likewise too broad, particularly in that it does not specify the use of a computer. The term [[computer-aided]], rather than computer-assisted, is used in the same manner as [[computer-aided design]].&lt;ref&gt;Christopher Ariza: An Open Design for Computer-Aided Algorithmic Music Composition, Universal-Publishers Boca Raton, Florida, 2005, p. 5&lt;/ref&gt;

==Machine improvisation==
{{See also|Machine learning|Machine listening|Artificial intelligence|Computer models of musical creativity}}
Machine improvisation uses computer algorithms to create [[improvisation]] on existing music materials. This is usually done by sophisticated recombination of musical phrases extracted from existing music, either live or pre-recorded. In order to achieve credible improvisation in particular style, machine improvisation uses [[machine learning]] and [[pattern matching]] algorithms to analyze existing musical examples. The resulting patterns are then used to create new variations &quot;in the style&quot; of the original music, developing a notion of stylistic reinjection.
This is different from other improvisation methods with computers that use [[algorithmic composition]] to generate new music without performing analysis of existing music examples.&lt;ref&gt;Mauricio Toro, Carlos Agon, Camilo Rueda, Gerard Assayag. &quot;[http://www.jatit.org/volumes/Vol86No2/17Vol86No2.pdf GELISP: A Framework to Represent Musical Constraint Satisfaction Problems and Search Strategies]&quot;, ''Journal of Theoretical and Applied Information Technology'' 86, no. 2 (2016): 327–331.&lt;/ref&gt;

===Statistical style modeling===
Style modeling implies building a computational representation of the musical surface that captures important stylistic features from data. Statistical approaches are used to capture the redundancies in terms of pattern dictionaries or repetitions, which are later recombined to generate new musical data. Style mixing can be realized by analysis of a database containing multiple musical examples in different styles. Machine Improvisation builds upon a long musical tradition of statistical modeling that began with Hiller and Isaacson's ''Illiac Suite for String Quartet'' (1957) and Xenakis' uses of [[Markov chains]] and [[stochastic processes]]. Modern methods include the use of [[lossless data compression]] for incremental parsing, [[prediction suffix tree]], [[string searching]] and more. &lt;ref&gt;S. Dubnov, G. Assayag, O. Lartillot, G. Bejerano, &quot;Using Machine-Learning Methods for Musical Style Modeling&quot;, IEEE Computers, 36 (10), pp. 73–80, Oct. 2003.&lt;/ref&gt; Style mixing is possible by blending models derived from several musical sources, with the first style mixing done by S. Dubnov in a piece NTrope Suite using Jensen-Shannon joint source model.&lt;ref&gt;DUBNOV, S. (1999). Stylistic randomness: About composing NTrope Suite. Organised Sound, 4(2), 87–92. {{doi|10.1017/S1355771899002046}}&lt;/ref&gt; Later the use of [[factor oracle]] algorithm  (basically a ''factor oracle'' is a finite state automaton constructed in linear time and space in an incremental fashion)&lt;ref&gt;{{cite book |url=https://books.google.com/?id=JtMYxwzUL00C&amp;pg=PA295&amp;dq=Factor+oracle:+a+new+structure+for+pattern+matching#v=onepage&amp;q=Factor%20oracle%3A%20a%20new%20structure%20for%20pattern%20matching&amp;f=false |editor1=Jan Pavelka |editor2=Gerard Tel |editor3=Miroslav Bartosek |quote=Lecture Notes in Computer Science 1725 |pages=291–306 |publisher=Springer-Verlag, Berlin |year=1999 |isbn=978-3-540-66694-3 |title=Factor oracle: a new structure for pattern matching; Proceedings of SOFSEM'99; Theory and Practice of Informatics |accessdate=4 December 2013}}&lt;/ref&gt; was adopted for music by Assayag and Dubnov &lt;ref&gt; Using factor oracles for machine improvisation
G Assayag, S Dubnov
Soft Computing 8 (9), 604–610&lt;/ref&gt; and became the basis for several systems that use stylistic re-injection.&lt;ref&gt;Memex and composer duets: computer-aided composition using style mixing S Dubnov, G Assayag Open Music composers book 2, 53–66&lt;/ref&gt;

===Implementations===

The first implementation of statistical style modeling was the LZify method in Open Music&lt;ref&gt;G. Assayag, S. Dubnov, O. Delerue, &quot;Guessing the Composer's Mind : Applying Universal Prediction to Musical Style&quot;, In Proceedings of International Computer Music Conference, Beijing, 1999.&lt;/ref&gt;, followed by the Continuator system that implemented interactive machine improvisation that interpreted the LZ incremental parsing in terms of [[Markov models]] and used it for real time style modeling &lt;ref&gt;{{Cite web |url=http://francoispachet.fr/continuator/continuator.html |title=Archived copy |access-date=19 May 2014 |archive-url=https://web.archive.org/web/20141101121138/http://francoispachet.fr/continuator/continuator.html |archive-date=1 November 2014 |url-status=dead |df=dmy-all }}&lt;/ref&gt; developed by [[François Pachet]] at Sony CSL Paris in 2002&lt;ref&gt;Pachet, F., [http://www.csl.sony.fr/downloads/papers/uploads/pachet-02f.pdf The Continuator: Musical Interaction with Style] {{Webarchive|url=https://web.archive.org/web/20120414183356/http://www.csl.sony.fr/downloads/papers/uploads/pachet-02f.pdf |date=14 April 2012 }}. In ICMA, editor, Proceedings of ICMC, pages 211–218, Göteborg, Sweden, September 2002. ICMA. Best paper award.&lt;/ref&gt;&lt;ref&gt;Pachet, F. [http://www.csl.sony.fr/downloads/papers/2002/pachet02b.pdf Playing with Virtual Musicians: the Continuator in practice] {{Webarchive|url=https://web.archive.org/web/20120414183418/http://www.csl.sony.fr/downloads/papers/2002/pachet02b.pdf |date=14 April 2012 }}. IEEE Multimedia,9(3):77–82 2002.&lt;/ref&gt;. Matlab implementation of the Factor Oracle machine improvisation can be found as part of [[Computer Audition]] toolbox. There is also an NTCC implementation of the Factor Oracle machine improvisation.&lt;ref&gt;
M Toro, C Rueda, C Agón, G Assayag. NTCCRT: A concurrent constraint framework for soft-real time music interaction. 
Journal of Theoretical &amp; Applied Information Technology Vol. 82 Issue 1, p184-193. 2015&lt;/ref&gt;

OMax is a software environment developed in IRCAM. OMax uses [[OpenMusic]] and Max. It is based on researches on stylistic modeling carried out by Gerard Assayag and Shlomo Dubnov and on researches on improvisation with the computer by G. Assayag, M. Chemillier and G. Bloch (a.k.a. the ''OMax Brothers'') in the Ircam Music Representations group.&lt;ref&gt;{{cite web|url=http://omax.ircam.fr/|title=The OMax Project Page|website=omax.ircam.fr|access-date=2018-02-02}}&lt;/ref&gt;
One of the problems in modeling audio signals with factor oracle is the symbolization of features from continuous values to a discrete alphabet. This problem was solved in the Variable Markov Oracle (VMO) available as python implementation &lt;ref&gt;Guided music synthesis with variable markov oracle
C Wang, S Dubnov,, Tenth Artificial Intelligence and Interactive Digital Entertainment Conference, 2014 &lt;/ref&gt;, using an information rate criteria for finding the optimal or most informative representation&lt;ref&gt;S Dubnov, G Assayag, A Cont, Audio oracle analysis of musical information rate IEEE Fifth International Conference on Semantic Computing, 567–57, 2011 &lt;/ref&gt;.

===Musicians working with machine improvisation===
{{Indiscriminate list|section|date=May 2019}}
*Gerard Assayag (IRCAM, France)
*[[Jeremy Castro Baguyos|Jeremy Baguyos]] (University of Nebraska at Omaha, US)
*Tim Blackwell (Goldsmiths College, Great Britain)
*George Bloch (Composer, France)
*Marc Chemiller (IRCAM/CNRS, France)
*[[Nick Collins (composer)|Nick Collins]] (University of Sussex, UK)
*Shlomo Dubnov (composer, Israel / US)
*[[Mari Kimura]] ([[Juilliard]], New York City)
*Amanuel Zarzowski (composer Los Angeles/San Diego)
*[[George Lewis (trombonist)|George Lewis]] (Columbia University, New York City)
*[[Bernard Lubat]] (pianist, France)
*[[François Pachet]] (Sony CSL, France)
*Joel Ryan (Institute of Sonology, Netherlands)
*[[Michel Waisvisz]] (STEIM, Netherlands)
*David Wessel (CNMAT, California)
*Michael Young (Goldsmiths College, Great Britain)
*[[Pietro Grossi]] (CNUCE, Institute of the National Research Council, Pisa, Italy)
*Toby Gifford and Andrew Brown (Griffith University, Brisbane, Australia)
*Davis Salks (jazz composer, Hamburg, PA, US)
*Doug Van Nort (electroacoustic improviser, Montreal/New York)

==Live coding==
{{Main|Live coding}}
Live coding&lt;ref&gt;{{Cite journal | last1 = Collins | first1 = N. | last2 = McLean | first2 = A. | last3 = Rohrhuber | first3 = J. | last4 = Ward | first4 = A. | title = Live coding in laptop performance | doi = 10.1017/S135577180300030X | journal = Organised Sound | volume = 8 | issue = 3 | pages = 321–330 | year = 2004 | pmid =  | pmc = }}&lt;/ref&gt; (sometimes known as 'interactive programming', 'on-the-fly programming',&lt;ref&gt;Wang G. &amp; Cook P. (2004) [http://soundlab.cs.princeton.edu/publications/on-the-fly_nime2004.pdf &quot;On-the-fly Programming: Using Code as an Expressive Musical Instrument&quot;], In ''Proceedings of the 2004 International Conference on New Interfaces for Musical Expression (NIME)'' (New York: NIME, 2004).&lt;/ref&gt; 'just in time programming') is the name given to the process of writing [[software]] in realtime as part of a [[performance]]. Recently it has been explored as a more rigorous alternative to laptop musicians who, live coders often feel, lack the charisma and pizzazz of [[musicians]] performing live.&lt;ref&gt;{{Cite journal |doi=10.1080/0749446032000156919 |author=Collins, N. |year=2003 |title=Generative Music and Laptop Performance |url= |journal=Contemporary Music Review |volume=22 |issue=4 |pages=67–79}}&lt;/ref&gt;

==See also==
{{col-begin}}
{{col-2}}
* [[Acousmatic art]]
* [[Chiptune]]
* [[Comparison of audio synthesis environments]]
* [[Csound]]
* [[Digital audio workstation]]
* [[Digital synthesizer]]
* [[Electronic music]]
* [[Emily Howell]]
* [[Fast Fourier Transform]]
* [[Human-computer interaction]]
* [[Interactive music]]
* [[Laptronica]]
* [[Media synthesis (AI)]]
* [[List of music software]]
* [[Module file]]
* [[Music information retrieval]]
{{col-2}}
* [[Music Macro Language]]
* [[Music notation software]]
* [[Music sequencer]]
* [[New interfaces for musical expression]]
* [[Physical modeling]]
* [[Programming (music)]]
* [[Sampling (music)]]
* [[Sound and music computing|Sound and Music Computing]]
* [[Sound synthesis]]
* [[Music tracker|Tracker]]
* [[Vaporwave]]
* [[Video game music]]
* [[Vocaloid]]
{{col-end}}

==References==
{{reflist}}

==Further reading==
* Ariza, C. 2005. &quot;[https://web.archive.org/web/20070927001256/http://www.flexatone.net/docs/nlcaacs.pdf Navigating the Landscape of Computer-Aided Algorithmic Composition Systems: A Definition, Seven Descriptors, and a Lexicon of Systems and Research].&quot; In ''Proceedings of the International Computer Music Conference''. San Francisco: International Computer Music Association. 765–772.
* Ariza, C. 2005. ''[https://web.archive.org/web/20110606061708/http://www.flexatone.net/docs/odcaamca.pdf An Open Design for Computer-Aided Algorithmic Music Composition: athenaCL]''. Ph.D. Dissertation, New York University.
* {{cite journal|doi=10.2307/3680818|jstor=3680818|title=Abstracting the Future: The Search for Musical Constructs|journal=Computer Music Journal|volume=20|issue=3|pages=24–27|year=1996|last1=Berg|first1=Paul}}
* {{Cite book|title=The Csound Book: Perspectives in Software Synthesis, Sound Design, Signal Processing, and Programming|editor=Boulanger, Richard|publisher=The MIT Press|date=March 6, 2000|page=740|isbn=978-0-262-52261-8|url=http://csounds.com/shop/csound-book|accessdate=3 October 2009|archive-url=https://web.archive.org/web/20100102064621/http://csounds.com/shop/csound-book|archive-date=2 January 2010|url-status=dead|df=dmy-all}}
* [[Joel Chadabe|Chadabe, Joel]]. 1997. ''Electric Sound: The Past and Promise of Electronic Music''. Upper Saddle River, New Jersey: Prentice Hall.
* Chowning, John. 1973. &quot;The Synthesis of Complex Audio Spectra by Means of Frequency Modulation&quot;. ''Journal of the Audio Engineering Society'' 21, no. 7:526–34.
* {{Cite book| last = Collins | first = Nick | title = Introduction to Computer Music | publisher = Wiley | location = Chichester | year = 2009 | isbn = 978-0-470-71455-3}}
* {{Cite book|last=Dodge|first=Charles|author2=Jerse|others=Thomas A.|title=Computer Music: Synthesis, Composition and Performance|publisher=Schirmer Books|location=New York|year=1997|edition=2nd|page=453|isbn=978-0-02-864682-4}}
* Doornbusch, P. 2015. &quot;[http://www.doornbusch.net/chronology/ A Chronology / History of Electronic and Computer Music and Related Events 1906 - 2015]&quot;
* Doornbusch, P. 2017. &quot;[https://www.academia.edu/34234640/MuSA_2017_Conference_-_Early_Computer_Music_Experiments_in_Australia_England_and_the_USA MuSA 2017 – Early Computer Music Experiments in Australia, England and the USA]&quot;
* {{Cite book | last = Heifetz | first = Robin | title = On the Wires of Our Nerves | publisher = Bucknell University Press | location = Lewisburg Pa. | year = 1989 | isbn = 978-0-8387-5155-8 | url-access = registration | url = https://archive.org/details/onwiresofournerv00heif }}
* {{cite journal| title = A Functional Taxonomy of Music Generation Systems
| author = D. Herremans
| author2 = C.H. Chuan
| author3 = E. Chew
| year = 2017
| journal = ACM Computing Surveys
| volume = 50
| issue = 5
| doi = 10.1109/TAFFC.2017.2737984
| pages = 69:1–30| arxiv = 1812.04832
}}
* {{Cite book| last = Manning | first = Peter | title = Electronic and Computer Music | edition=revised and expanded | publisher = Oxford University Press | location = Oxford Oxfordshire | year = 2004 | isbn = 978-0-19-517085-6 }}
* Perry, Mark, and Thomas Margoni. 2010. &quot;[http://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID1753242_code1383303.pdf?abstractid=1647584&amp;mirid=1 From Music Tracks to Google Maps: Who Owns Computer-Generated Works?]&quot;. ''Computer Law and Security Review'' 26: 621–29.
* {{Cite book| last = Roads | first = Curtis | title = The Computer Music Tutorial | publisher = MIT Press | location = Cambridge | year = 1994 | isbn = 978-0-262-68082-0 }}
* {{cite journal|doi=10.1162/014892601300126106|title=A Few Remarks on Algorithmic Composition|journal=Computer Music Journal|volume=25|pages=48–53|year=2001|last1=Supper|first1=Martin}}
* {{Cite book| last = Xenakis | first = Iannis | title = Formalized Music: Thought and Mathematics in Composition | series = Harmonologia Series No. 6 | publisher = Pendragon Pr | location = Hillsdale, NY | year = 2001 | isbn = 978-1-57647-079-4 }}

{{Computer music}}

[[Category:Computer music]]
[[Category:Computer music software]]</text>
      <sha1>ridzhnnmd5n3m28hb467envjbehdrsh</sha1>
    </revision>
  </page>
